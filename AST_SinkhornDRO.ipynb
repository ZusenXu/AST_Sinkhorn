{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "from typing import Dict, Union, Tuple, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Generation\n",
    "\n",
    "def generate_imbalanced_data(n_samples=1000, noise_level=0.01):\n",
    "    \"\"\"\n",
    "    Generates a 2D imbalanced dataset for binary classification.\n",
    "    The decision boundary is linear (x1 - 2*x2 = 0).\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n_samples, 2).astype(np.float32)\n",
    "    decision_boundary = X[:, 0] - 2 * X[:, 1]\n",
    "    noise = noise_level * np.random.randn(n_samples)\n",
    "    y = (decision_boundary + noise > 0).astype(np.float32)\n",
    "    \n",
    "    # Create imbalance\n",
    "    minority_class_indices = np.where(y == 1)[0]\n",
    "    majority_class_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Intentionally create a small dataset to highlight model differences\n",
    "    n_minority = int(n_samples / 4 * 0.1) # e.g., 12\n",
    "    n_majority = int(n_samples / 4 * 0.9) # e.g., 108\n",
    "    \n",
    "    if len(minority_class_indices) < n_minority or len(majority_class_indices) < n_majority:\n",
    "        warnings.warn(\"Not enough samples to create the desired imbalance. Using all available.\")\n",
    "        n_minority = min(n_minority, len(minority_class_indices))\n",
    "        n_majority = min(n_majority, len(majority_class_indices))\n",
    "\n",
    "    selected_minority = np.random.choice(minority_class_indices, n_minority, replace=False)\n",
    "    selected_majority = np.random.choice(majority_class_indices, n_majority, replace=False)\n",
    "    \n",
    "    selected_indices = np.concatenate([selected_minority, selected_majority])\n",
    "    np.random.shuffle(selected_indices)\n",
    "    \n",
    "    return X[selected_indices], y[selected_indices]\n",
    "\n",
    "def generate_balanced_data(n_samples=1000, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generates a 2D balanced dataset for binary classification.\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n_samples, 2).astype(np.float32)\n",
    "    decision_boundary = X[:, 0] - 2 * X[:, 1]\n",
    "    noise = noise_level * np.random.randn(n_samples)\n",
    "    y = (decision_boundary + noise > 0).astype(np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Core Modules and Base Classes\n",
    "\n",
    "class DROError(Exception):\n",
    "    \"\"\"Base exception class for custom DRO models.\"\"\"\n",
    "    pass\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Linear Model for regression or classification tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, output_dim: int = 1, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the linear model.\"\"\"\n",
    "        return self.linear(x)\n",
    "\n",
    "class BaseLinearDRO:\n",
    "    \"\"\"A minimal base class for structure and type hinting.\"\"\"\n",
    "    def __init__(self, input_dim: int, model_type: str, fit_intercept: bool):\n",
    "        self.input_dim = input_dim\n",
    "        self.model_type = model_type.lower()\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def _to_tensor(self, data: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"Convert numpy array to a tensor on the correct device.\"\"\"\n",
    "        return torch.as_tensor(data, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def _validate_inputs(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"Validate input dimensions.\"\"\"\n",
    "        if X.ndim == 1: X = X.reshape(-1, self.input_dim)\n",
    "        if y.ndim == 1: y = y.reshape(-1, 1)\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise DROError(f\"X and y must have the same number of samples. Got X: {X.shape[0]}, y: {y.shape[0]}\")\n",
    "        if X.shape[1] != self.input_dim:\n",
    "            raise DROError(f\"Expected input_dim={self.input_dim} features for X, got {X.shape[1]}\")\n",
    "\n",
    "    def _create_dataloader(self, X: np.ndarray, y: np.ndarray, batch_size: int) -> DataLoader:\n",
    "        \"\"\"Create a PyTorch DataLoader from numpy data.\"\"\"\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        y_tensor = self._to_tensor(y)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    def _extract_parameters(self) -> Dict[str, np.ndarray | None]:\n",
    "        \"\"\"Extract model parameters as numpy arrays.\"\"\"\n",
    "        theta = self.model.linear.weight.detach().cpu().numpy().flatten()\n",
    "        bias_val = None\n",
    "        if self.model.linear.bias is not None:\n",
    "            bias_val = self.model.linear.bias.detach().cpu().numpy()\n",
    "        return {\"theta\": theta, \"bias\": bias_val}\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate raw model predictions (logits).\"\"\"\n",
    "        # A dummy y is created for validation, it is not used.\n",
    "        self._validate_inputs(X, np.zeros(X.shape[0]))\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions_logits = self.model(X_tensor).cpu().numpy()\n",
    "        return predictions_logits\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"Evaluate model performance on given data.\"\"\"\n",
    "        y_pred_logits = self.predict(X) \n",
    "        y_true_flat = y.flatten()\n",
    "        pred_labels_flat = (y_pred_logits.flatten() >= 0).astype(int)\n",
    "        accuracy = accuracy_score(y_true_flat, pred_labels_flat)\n",
    "        f1 = f1_score(y_true_flat, pred_labels_flat, average='macro', zero_division=0)\n",
    "        return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Implementation\n",
    "\n",
    "class SinkhornLinearDRO(BaseLinearDRO):\n",
    "    \"\"\"Sinkhorn Distributionally Robust Optimization with Linear Models.\"\"\"\n",
    "    def __init__(self,\n",
    "                input_dim: int,\n",
    "                fit_intercept: bool = True, \n",
    "                reg_param: float = 1e-3,\n",
    "                lambda_param: float = 1e2,\n",
    "                max_iter: int = 1000,\n",
    "                learning_rate: float = 1e-2,\n",
    "                k_sample_max: int = 5,\n",
    "                device: str = \"cpu\"):\n",
    "        super().__init__(input_dim, \"logistic\", fit_intercept)\n",
    "        self.reg_param = reg_param\n",
    "        self.lambda_param = lambda_param\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k_sample_max = k_sample_max\n",
    "        self.device = torch.device(device if device == \"cuda\" and torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = LinearModel(input_dim, output_dim=1, bias=fit_intercept).to(self.device)\n",
    "\n",
    "    def _compute_loss(self, predictions, targets, m, lambda_reg):\n",
    "        \"\"\"Computes the Sinkhorn loss.\"\"\"\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        residuals = criterion(predictions, targets) / lambda_reg\n",
    "        residual_matrix = residuals.view(m, -1)\n",
    "        return torch.mean(torch.logsumexp(residual_matrix, dim=0) - math.log(m)) * lambda_reg\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Tuple[Dict[str, np.ndarray], List[float]]:\n",
    "        \"\"\"Train the model using standard SGD and return loss history.\"\"\"\n",
    "        self._validate_inputs(X, y)\n",
    "        dataloader = self._create_dataloader(X, y.reshape(-1,1), batch_size=1)\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        lambda_reg = self.lambda_param * self.reg_param\n",
    "        \n",
    "        loss_history = []\n",
    "        self.model.train()\n",
    "        for epoch in range(self.max_iter):\n",
    "            for data, target in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Fixed number of samples for SGD\n",
    "                m = 2 ** self.k_sample_max\n",
    "                \n",
    "                expanded_data = data.repeat(m, 1)\n",
    "                noise = torch.randn_like(expanded_data) * math.sqrt(self.reg_param)\n",
    "                noisy_data = expanded_data + noise\n",
    "                repeated_target = target.repeat(m, 1)\n",
    "\n",
    "                predictions = self.model(noisy_data)\n",
    "                loss = self._compute_loss(predictions, repeated_target, m, lambda_reg)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "        return self._extract_parameters(), loss_history\n",
    "\n",
    "class AdjustedSteinTransport:\n",
    "    \"\"\"Implements Adjusted Stein Transport using a Gaussian RBF kernel.\"\"\"\n",
    "    def __init__(self, lam=1e-2, n_steps=50, n_svgd=1, dt=0.02, dt_svgd=0.02, clip_value=1e4):\n",
    "        self.lam = lam\n",
    "        self.n_steps = n_steps\n",
    "        self.n_svgd = n_svgd\n",
    "        self.dt = dt\n",
    "        self.dt_svgd = dt_svgd\n",
    "        # Add a clipping value to prevent gradient explosion\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def _rbf_kernel(self, X):\n",
    "        \"\"\"Computes the Gaussian RBF kernel and its derivatives.\"\"\"\n",
    "        N, D = X.shape\n",
    "        pairwise_sq_dists = squareform(pdist(X, 'sqeuclidean'))\n",
    "        # Add a small epsilon to h2 to avoid division by zero\n",
    "        h2 = 0.5 * np.median(pairwise_sq_dists) / np.log(N + 1)\n",
    "        h2 = np.max([h2, 1e-6]) \n",
    "        K = np.exp(-pairwise_sq_dists / (2 * h2))\n",
    "        X_diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n",
    "        grad_K_x = -X_diff / h2 * K[..., np.newaxis]\n",
    "        grad_K_y = X_diff / h2 * K[..., np.newaxis]\n",
    "        trace_H = (D / h2 - pairwise_sq_dists / h2**2) * K\n",
    "        return K, grad_K_x, grad_K_y, trace_H\n",
    "\n",
    "    def update(self, X0, grad_log_prior, neg_log_likelihood, grad_neg_log_likelihood):\n",
    "        \"\"\"Executes the full Adjusted Stein Transport algorithm.\"\"\"\n",
    "        X = np.copy(X0)\n",
    "        N, _ = X.shape\n",
    "\n",
    "        for n in range(self.n_steps):\n",
    "            t_n = n * self.dt\n",
    "            grad_log_pi_t = lambda x: grad_log_prior(x) - t_n * grad_neg_log_likelihood(x)\n",
    "            \n",
    "            # --- SVGD Adjustment Step ---\n",
    "            for _ in range(self.n_svgd):\n",
    "                P_svgd = grad_log_pi_t(X)\n",
    "                # Clip gradients to prevent explosion\n",
    "                np.clip(P_svgd, -self.clip_value, self.clip_value, out=P_svgd)\n",
    "                K_svgd, _, grad_K_y_svgd, _ = self._rbf_kernel(X)\n",
    "                svgd_grad = (K_svgd @ P_svgd + np.sum(grad_K_y_svgd, axis=1)) / N\n",
    "                X += self.dt_svgd * svgd_grad\n",
    "\n",
    "            # --- Main Stein Transport Step ---\n",
    "            P_transport = grad_log_pi_t(X)\n",
    "            # FIX: Clip the gradients to prevent overflow in the subsequent matmul\n",
    "            np.clip(P_transport, -self.clip_value, self.clip_value, out=P_transport)\n",
    "            \n",
    "            K, grad_K_x, grad_K_y, trace_H = self._rbf_kernel(X)\n",
    "            term1 = np.einsum('id,ijd->ij', P_transport, grad_K_y)\n",
    "            term2 = np.einsum('jd,ijd->ij', P_transport, grad_K_x)\n",
    "            term3 = (P_transport @ P_transport.T) * K\n",
    "            xi_matrix = term1 + term2 + term3 + trace_H\n",
    "            h_vec = neg_log_likelihood(X).flatten()\n",
    "            h_centered = h_vec - np.mean(h_vec)\n",
    "            A = xi_matrix / N + self.lam * np.identity(N)\n",
    "            \n",
    "            try:\n",
    "                phi_weights = np.linalg.solve(A, h_centered)\n",
    "            except np.linalg.LinAlgError:\n",
    "                # If solver fails, use pseudo-inverse as a fallback\n",
    "                warnings.warn(\"Linear solver failed. Using pseudo-inverse.\")\n",
    "                phi_weights = np.linalg.pinv(A) @ h_centered\n",
    "                \n",
    "            term_a = (K * phi_weights[np.newaxis, :]) @ P_transport\n",
    "            term_b = np.einsum('j,ijd->id', phi_weights, grad_K_y)\n",
    "            transport_grad = (term_a + term_b) / N\n",
    "            X += self.dt * transport_grad\n",
    "            \n",
    "        return X\n",
    "\n",
    "class SinkhornDROLogisticAST(BaseLinearDRO):\n",
    "    \"\"\"Sinkhorn DRO for Logistic Regression using Adjusted Stein Transport (AST).\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 fit_intercept: bool = True,\n",
    "                 epsilon: float = 0.1,\n",
    "                 lambda_dro: float = 1.0,\n",
    "                 ast_lam: float = 1,\n",
    "                 ast_n_steps: int = 20,\n",
    "                 ast_n_svgd: int = 1,\n",
    "                 num_ast_samples: int = 10,\n",
    "                 max_iter: int = 100,\n",
    "                 learning_rate: float = 0.01,\n",
    "                 device: str = \"cpu\"):\n",
    "        super().__init__(input_dim, \"logistic\", fit_intercept)\n",
    "        self.epsilon = epsilon\n",
    "        self.lambda_dro = lambda_dro\n",
    "        # Pass a clipping value to the AST constructor\n",
    "        self.ast_params = {'lam': ast_lam, 'n_steps': ast_n_steps, 'n_svgd': ast_n_svgd, \n",
    "                           'dt': 1/ast_n_steps, 'dt_svgd': 1/ast_n_steps/ast_n_svgd,\n",
    "                           'clip_value': 1e4}\n",
    "        self.num_ast_samples = num_ast_samples\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device(device if device == \"cuda\" and torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = LinearModel(self.input_dim, output_dim=1, bias=self.fit_intercept).to(self.device)\n",
    "\n",
    "    def _ast_sampler(self, x_orig, y_orig, model):\n",
    "        \"\"\"Generates worst-case samples using the AST algorithm.\"\"\"\n",
    "        ast = AdjustedSteinTransport(**self.ast_params)\n",
    "        \n",
    "        def grad_log_prior(x_np):\n",
    "            return -2.0 / self.epsilon * (x_np - x_orig.cpu().numpy())\n",
    "\n",
    "        def neg_log_likelihood(x_np):\n",
    "            x_torch = self._to_tensor(x_np)\n",
    "            # Handle cases where x_np has fewer samples than y_orig expects\n",
    "            num_samples = x_torch.shape[0]\n",
    "            y_torch = y_orig.repeat(num_samples, 1)\n",
    "            predictions = model(x_torch)\n",
    "            loss = nn.BCEWithLogitsLoss(reduction='none')(predictions, y_torch)\n",
    "            return (-loss / (self.lambda_dro * self.epsilon)).detach().cpu().numpy().flatten()\n",
    "\n",
    "        def grad_neg_log_likelihood(x_np):\n",
    "            x_torch = self._to_tensor(x_np).requires_grad_(True)\n",
    "            num_samples = x_torch.shape[0]\n",
    "            y_torch = y_orig.repeat(num_samples, 1)\n",
    "            predictions = model(x_torch)\n",
    "            # Use sum reduction for scalar output needed by autograd\n",
    "            f_x_theta = nn.BCEWithLogitsLoss(reduction='sum')(predictions, y_torch)\n",
    "            grad_f = torch.autograd.grad(f_x_theta, x_torch, retain_graph=True)[0]\n",
    "            return (-grad_f / (self.lambda_dro * self.epsilon)).detach().cpu().numpy()\n",
    "\n",
    "        mean = x_orig\n",
    "        std_dev = torch.sqrt(torch.tensor(self.epsilon / 2.0, device=self.device))\n",
    "        X0_torch = mean + std_dev * torch.randn(self.num_ast_samples, self.input_dim, device=self.device)\n",
    "        \n",
    "        final_particles_np = ast.update(\n",
    "            X0_torch.cpu().numpy(), \n",
    "            grad_log_prior, neg_log_likelihood, \n",
    "            grad_neg_log_likelihood\n",
    "        )\n",
    "        return self._to_tensor(final_particles_np)\n",
    "\n",
    "    def fit(self, X, y) -> Tuple[Dict[str, np.ndarray], List[float]]:\n",
    "        \"\"\"Train the model and return loss history.\"\"\"\n",
    "        self._validate_inputs(X, y)\n",
    "        dataloader = self._create_dataloader(X, y.reshape(-1,1), batch_size=1)\n",
    "        optimizer_theta = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        loss_history = []\n",
    "        self.model.train()\n",
    "        for epoch in range(self.max_iter):\n",
    "            for x_orig, y_orig in dataloader:\n",
    "                # Detach the model from the graph for the sampler to avoid nested autograd issues\n",
    "                self.model.eval()\n",
    "                worst_case_samples = self._ast_sampler(x_orig, y_orig, self.model)\n",
    "                self.model.train()\n",
    "\n",
    "                y_repeated = y_orig.repeat(self.num_ast_samples, 1)\n",
    "                predictions = self.model(worst_case_samples)\n",
    "                loss = nn.BCEWithLogitsLoss()(predictions, y_repeated)\n",
    "                \n",
    "                optimizer_theta.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_theta.step()\n",
    "                loss_history.append(loss.item())\n",
    "        return self._extract_parameters(), loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis and Plotting\n",
    "\n",
    "def analyze_decision_boundary(params, X, y, title):\n",
    "    \"\"\"Prints analysis of a model's decision boundary.\"\"\"\n",
    "    theta = np.array(params['theta'])\n",
    "    bias = params['bias'].item() if hasattr(params['bias'], 'item') and params['bias'] is not None else 0.0\n",
    "    \n",
    "    print(f\"\\n--- {title} Analysis ---\")\n",
    "    print(f\"Model parameters: theta=[{theta[0]:.4f}, {theta[1]:.4f}], bias={bias:.4f}\")\n",
    "    \n",
    "    logits = X @ theta + bias\n",
    "    preds = (logits >= 0).astype(np.float32)\n",
    "    distances = np.abs(logits)\n",
    "    near_boundary = distances < 0.1\n",
    "    \n",
    "    print(f\"Fraction of test samples near boundary: {np.mean(near_boundary):.2%}\")\n",
    "    acc, f1 = accuracy_score(y, preds), f1_score(y, preds)\n",
    "    print(f\"Accuracy on test set: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "def plot_decision_boundaries(X_train, y_train, params_dict, iteration):\n",
    "    \"\"\"Plots data and decision boundaries for multiple models.\"\"\"\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    \n",
    "    # Plot training data points\n",
    "    plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \n",
    "                c='royalblue', marker='o', label='Training Negative', alpha=0.7, edgecolors='w')\n",
    "    plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \n",
    "                c='crimson', marker='^', label='Training Positive', alpha=0.7, edgecolors='w')\n",
    "    \n",
    "    # Generate grid for plotting boundaries\n",
    "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "    xx = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "    # Define styles for plotting\n",
    "    styles = {'Sinkhorn': ('g', '-', 'Sinkhorn'), \n",
    "              'AST': ('purple', ':', 'AST')}\n",
    "\n",
    "    for name, params in params_dict.items():\n",
    "        if params is not None:\n",
    "            theta = np.array(params['theta'])\n",
    "            bias = params['bias'].item() if hasattr(params['bias'], 'item') and params['bias'] is not None else 0.0\n",
    "            \n",
    "            if abs(theta[1]) > 1e-6:\n",
    "                yy = -(theta[0] * xx + bias) / theta[1]\n",
    "                color, style, label = styles[name]\n",
    "                plt.plot(xx, yy, color=color, linestyle=style, linewidth=2.5,\n",
    "                         label=f'{label} (θ=[{theta[0]:.2f},{theta[1]:.2f}],b={bias:.2f})')\n",
    "    \n",
    "    # Plot true decision boundary: x1 - 2*x2 = 0  => x2 = 0.5 * x1\n",
    "    yy_true = 0.5 * xx\n",
    "    plt.plot(xx, yy_true, 'k-', linewidth=2, label='True Boundary')\n",
    "    \n",
    "    plt.xlabel('Feature 1', fontsize=12)\n",
    "    plt.ylabel('Feature 2', fontsize=12)\n",
    "    plt.title(f\"Decision Boundaries (Experiment {iteration+1}, N_train={len(X_train)})\", fontsize=14)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f'decision_boundaries_exp_{iteration+1}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_loss_convergence(loss_histories, iteration):\n",
    "    \"\"\"Plots the convergence of the objective function for different models.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    styles = {'Sinkhorn': ('g', '-'), 'AST': ('purple', ':')}\n",
    "    \n",
    "    for name, history in loss_histories.items():\n",
    "        if history:\n",
    "            color, style = styles[name]\n",
    "            # Use a moving average to smooth the curve for better visualization\n",
    "            window_size = len(history) // 20\n",
    "            if window_size > 0:\n",
    "                moving_avg = np.convolve(history, np.ones(window_size)/window_size, mode='valid')\n",
    "                plt.plot(moving_avg, color=color, linestyle=style, label=f'{name} (Smoothed)')\n",
    "            else:\n",
    "                plt.plot(history, color=color, linestyle=style, label=name)\n",
    "\n",
    "    plt.xlabel('Training Step (Theta Update)', fontsize=12)\n",
    "    plt.ylabel('Loss Value', fontsize=12)\n",
    "    plt.title(f'Loss Convergence (Experiment {iteration+1})', fontsize=14)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.yscale('log') # Use log scale for better visualization of convergence\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f'loss_convergence_exp_{iteration+1}.png', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running all experiments on device: '0'\n",
      "\n",
      "==================== Experiment 1/5 ====================\n",
      "Training data: 124 samples (9.7% positive)\n",
      "Test data: 2000 samples\n",
      "\n",
      "Training Sinkhorn DRO (SGD)...\n",
      "Sinkhorn DRO Final F1-Score: 0.8997\n",
      "\n",
      "Training AST Sampler DRO...\n",
      "AST DRO Final F1-Score: 0.9047\n",
      "\n",
      "--- Sinkhorn Analysis ---\n",
      "Model parameters: theta=[5.1626, -7.4302], bias=-2.1727\n",
      "Fraction of test samples near boundary: 0.75%\n",
      "Accuracy on test set: 0.9000, F1-Score: 0.8938\n",
      "\n",
      "--- AST Analysis ---\n",
      "Model parameters: theta=[5.2213, -7.7800], bias=-2.1418\n",
      "Fraction of test samples near boundary: 0.95%\n",
      "Accuracy on test set: 0.9050, F1-Score: 0.8996\n",
      "\n",
      "==================== Experiment 2/5 ====================\n",
      "Training data: 124 samples (9.7% positive)\n",
      "Test data: 2000 samples\n",
      "\n",
      "Training Sinkhorn DRO (SGD)...\n",
      "Sinkhorn DRO Final F1-Score: 0.9146\n",
      "\n",
      "Training AST Sampler DRO...\n",
      "AST DRO Final F1-Score: 0.9172\n",
      "\n",
      "--- Sinkhorn Analysis ---\n",
      "Model parameters: theta=[3.4257, -6.9202], bias=-1.5225\n",
      "Fraction of test samples near boundary: 1.40%\n",
      "Accuracy on test set: 0.9150, F1-Score: 0.9089\n",
      "\n",
      "--- AST Analysis ---\n",
      "Model parameters: theta=[3.3384, -6.9407], bias=-1.4670\n",
      "Fraction of test samples near boundary: 1.10%\n",
      "Accuracy on test set: 0.9175, F1-Score: 0.9118\n",
      "\n",
      "==================== Experiment 3/5 ====================\n",
      "Training data: 124 samples (9.7% positive)\n",
      "Test data: 2000 samples\n",
      "\n",
      "Training Sinkhorn DRO (SGD)...\n",
      "Sinkhorn DRO Final F1-Score: 0.9267\n",
      "\n",
      "Training AST Sampler DRO...\n",
      "AST DRO Final F1-Score: 0.9363\n",
      "\n",
      "--- Sinkhorn Analysis ---\n",
      "Model parameters: theta=[3.3601, -7.1112], bias=-1.4695\n",
      "Fraction of test samples near boundary: 1.10%\n",
      "Accuracy on test set: 0.9270, F1-Score: 0.9221\n",
      "\n",
      "--- AST Analysis ---\n",
      "Model parameters: theta=[3.7072, -7.7710], bias=-1.3953\n",
      "Fraction of test samples near boundary: 0.75%\n",
      "Accuracy on test set: 0.9365, F1-Score: 0.9329\n",
      "\n",
      "==================== Experiment 4/5 ====================\n",
      "Training data: 124 samples (9.7% positive)\n",
      "Test data: 2000 samples\n",
      "\n",
      "Training Sinkhorn DRO (SGD)...\n",
      "Sinkhorn DRO Final F1-Score: 0.9310\n",
      "\n",
      "Training AST Sampler DRO...\n",
      "AST DRO Final F1-Score: 0.9366\n",
      "\n",
      "--- Sinkhorn Analysis ---\n",
      "Model parameters: theta=[3.3326, -6.8902], bias=-1.4120\n",
      "Fraction of test samples near boundary: 1.00%\n",
      "Accuracy on test set: 0.9315, F1-Score: 0.9250\n",
      "\n",
      "--- AST Analysis ---\n",
      "Model parameters: theta=[3.5195, -7.1915], bias=-1.3216\n",
      "Fraction of test samples near boundary: 1.00%\n",
      "Accuracy on test set: 0.9370, F1-Score: 0.9314\n",
      "\n",
      "==================== Experiment 5/5 ====================\n",
      "Training data: 124 samples (9.7% positive)\n",
      "Test data: 2000 samples\n",
      "\n",
      "Training Sinkhorn DRO (SGD)...\n",
      "Sinkhorn DRO Final F1-Score: 0.9219\n",
      "\n",
      "Training AST Sampler DRO...\n",
      "AST DRO Final F1-Score: 0.9291\n",
      "\n",
      "--- Sinkhorn Analysis ---\n",
      "Model parameters: theta=[3.6716, -8.5110], bias=-1.7266\n",
      "Fraction of test samples near boundary: 0.65%\n",
      "Accuracy on test set: 0.9230, F1-Score: 0.9125\n",
      "\n",
      "--- AST Analysis ---\n",
      "Model parameters: theta=[3.8857, -8.7441], bias=-1.6238\n",
      "Fraction of test samples near boundary: 0.85%\n",
      "Accuracy on test set: 0.9300, F1-Score: 0.9211\n",
      "\n",
      "========================= Final Results over 5 Experiments =========================\n",
      "Sinkhorn Average F1-Score: 0.9188 ± 0.0110\n",
      "AST Average F1-Score: 0.9248 ± 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3268764/4120321280.py:73: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(list(scores.values()), labels=list(scores.keys()), patch_artist=True,\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAISCAYAAADRDjk/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqFUlEQVR4nO3de1yUZf7/8fcc5CQCiSgBnpgOqAUoKGmlmRZJWRqV1VbGtpZutpVtdiIPHX627TfLbV2r72oHq10rT6t917YoLcswETMPWIlFSiqQgidOM/fvD7/Md0YGHRRkZno9Hw8fI9d93dd9feYervncN/d93SbDMAwBAAAAkCSZ27oDAAAAgC8hQQYAAABckCADAAAALkiQAQAAABckyAAAAIALEmQAAADABQkyAAAA4IIEGQAAAHBBggwAAAC4IEEGWlmPHj1kMplkMpl07733Hrfun//8Z2ddq9V6Wvr3ww8/yGQyqUePHi3S3muvvSaTyaTbb7+9Wes1xO36LzQ0VDabTTk5Odq4cWOL9M9bu3bt0q233qq4uDhZrdaTigm+IT8/XxMmTFCfPn0UFRWloKAgde7cWUOGDNFTTz2lkpKStu6i32n4HQUC1en5BgYgSXrrrbf05z//WUFBQR6Xz5s37zT3yPdkZmYqNjZWkrR371599dVXeu211/TWW2/pzTff1A033NDqfTAMQ9dee63Wrl2r3r17a+jQoWrXrp0uuuiiVt82Ws7hw4f1u9/9Tv/4xz8kSbGxsbrooosUGRmp8vJyrV27Vp9++qmefPJJLViwQKNGjWrbDgPwGSTIwGmSnp6udevWaenSpbr++usbLf/iiy9UVFSk/v3766uvvmqDHvqGhx9+WJdcconz58rKSl1//fX68MMPNW7cOF122WU644wzWrUPP/74o9auXatu3brp66+/Pm1n89Fy6urqlJmZqdWrV+vMM8/USy+9pKuvvtqtTn19vRYvXqxHH31UP/zwQ9t01E9t3bq1rbsAtCousQBOk9/+9reSmj5LPHfuXLd6OCoyMlKvvPKKJKmqqkoffPBBq2+z4U/uPXv2JDn2U08++aRWr16tqKgoff75542SY0myWq26/vrrVVhYqCFDhrRBL/1XUlKSkpKS2robQKshQQZOk/PPP1/p6en6z3/+o127drktO3jwoN555x0lJCTo8ssvP247v/zyix599FH16dNHYWFh6tChg9LS0vTss8/qyJEjTa63fPlyDRkyRB06dFBkZKQuvvhiLV269IT93rdvn6ZOnarU1FR16NBBYWFhOv/88/XUU0/p8OHD3gV/inr06KGOHTtKUqMzfQUFBfrNb36jbt26KTg4WB07dlRmZqb+53/+p8m2TCaTfvjhBy1dulSXXnqpOnbsKJPJ5Lx+uiFZWrVqlds10a7bPnz4sJ555hn169fP+b706dNHubm52rdvX6Ptul7rbbfbNXPmTPXt21fh4eHOazlXrlwpk8mkSy65RDU1NZo+fbrOOecchYSEqFu3bnrooYdUXV0t6eiZ9T/+8Y9KTExUSEiIevTooWnTpqm+vr7RtsvKyvSXv/xFWVlZ6tmzp0JDQxUREaH09HT96U9/crZ5LNfrTBcuXKiLLrpIERERat++vS688MIm32Pp6NnZefPmafjw4erUqZOCg4OVkJCg4cOH68UXX/S4Tl5enq699lqdeeaZzuuER48erTVr1jS5HU8OHDigWbNmSZKmTJminj17Hrd+eHi4+vbt26j8gw8+0FVXXaXOnTsrKChIcXFxGjNmjNatW+exnUsuuUQmk0krV67Ul19+qSuvvFLR0dHq0KGDhgwZos8++8xZd8WKFRo2bJjOOOMMhYeH67LLLtP69esbten6uamvr9ezzz6rPn36KDQ0VJ06ddINN9ygoqIij/1Zu3atJk+erAEDBig2NlZBQUHq0qWLRo4cqY8++sjjOq73EPzyyy+67777ZLPZFBwc7PaXnaauQf7555917733Oj+3YWFh6tq1q4YNG6b/+q//arKfN9xwg+Li4pz7feTIkfrwww891r/99tudv687duzQrbfeqtjYWAUHB8tmsyk3N1c1NTUe1wW8ZgBoVd27dzckGZ999pnxt7/9zZBkPPXUU2515s6da0gyHnvsMWPHjh2GJMNisTRqa/v27c72YmJijOzsbOPqq682OnToYEgy+vXrZ/zyyy+N1ps5c6YhyZBkDBgwwLjpppuM9PR0Q5IxadIkQ5LRvXv3Rutt3rzZ6Nq1qyHJOPPMM40rrrjCGDlypNGlSxdDkpGammrs37/fbZ1XX33VkGSMHTu2We9TQ/8++eSTRsvsdrsRHBxsSDJmzpzpLH/hhRcMs9ns7Mt1111nXHTRRUZQUJAhyZg+fXqjthrev4kTJxqSjPT0dOOmm24yhgwZYnz66afG2LFjjczMTEOS0aVLF2Ps2LHOf2VlZYZhGEZFRYWRmppqSDIiIiKMq6++2sjOzjY6depkSDJ69uxp7Nixw227Dfu1W7duxtVXX20EBQUZw4YNM2666SYjOTnZMAzD+OSTTwxJxsCBA40hQ4Y4277qqquMyMhIQ5Jx1VVXGRUVFca5557r/AxcfvnlRkhIiCHJGD9+fKOY58+fb0gy4uPjjSFDhhg33nijMWzYMCM8PNy5verq6ib3yZQpUwyTyWRceOGFxpgxY4yUlBRDkmEymYxFixY1Wm///v3GRRddZEgy2rVrZwwZMsS46aabjKFDhxoxMTGGp6+eBx54wJBkmM1mY8CAAcb1119vZGRkGCaTybBYLMa8efMardOUpUuXOvtXXl7u9XqucnNznW1ceOGFxk033eTc5xaLxZg7d26jdYYMGWJIMv74xz8aVqvV6Nu3rzFmzBjnesHBwcbnn39u/PWvfzXMZrMxaNAg44YbbjDOOeccQ5IRHh5ufPfdd25tNnxuunfvblx77bVGu3btjOHDhxs33nijkZiY6Fzviy++aNSfYcOGGWaz2Tj//PONrKws4/rrrzf69evn3K8vvPBCo3Uafn+vvPJKo2fPnsYZZ5xhXH311cb1119v/OY3v3HWa2jD1c8//2zExcU5P+fXXHONMWbMGOPiiy82OnbsaERGRjba3iuvvOL8He7bt69x0003GYMGDXK2P23atEbrjB071pBk3HvvvUZERITRvXt344YbbjCGDx9uhIaGGpKMUaNGNblvAW+QIAOtzDVB3r9/vxEaGmqcddZZbnUuvPBCw2QyGdu3bz9ugpyRkWFIMq6++mrj4MGDzvK9e/c6v/huvvlmt3W+/vprw2KxGGaz2Xj33Xfdlr355puGyWTymCAfPnzYsNlshiQjNzfXqKmpcS47dOiQcdNNNxmSjJycHLf1WiNBXr58uXP5xx9/bBiGYaxYscIwmUxGp06djFWrVrnV37hxo5GQkGBIMlauXOm2rGF/WCwWY+nSpR770pCoDhkyxOPyMWPGGJKMjIwMtwTswIEDxogRIwxJxqBBg9zWadivkoyEhARj27ZtTW634UDGte0ffvjBOOOMMwxJxvnnn2+MHDnSOHTokHP5V199ZVitVsNsNhs//vijW7tbtmwx1qxZ02h7v/zyi3H55Zcbkoxnn3220fKGvkRFRRlffvml27KpU6cakoxzzjmn0XrXXnutM+E59kChrq7OWLJkiVvZK6+8YkgyzjrrLOPrr792W7Zq1SqjQ4cORlBQkPHtt9822pYnjz/+uCHJSExM9Kr+sf79738bkoyQkBDjP//5j9uyv//9787Ef9OmTW7LGhJkk8lkzJ8/321Zw4Houeeea4SHhxsfffSRc1l9fb2RnZ1tSDJ+97vfua3n+rnp1KmT2/tTX19v3HPPPc7f32MPcv7nf/7HKC0tbRTfF198YURERBjt2rUzdu7c6bas4fdXkjFs2DCjsrLS43vkKUGePn26Icm48847DYfD4bastrbWLWbDOPp7arVaDZPJZLzxxhuN+t5woHvsPmhIkBtOKtTX1zuXffPNN0b79u0NSR4PGgBvkSADrcw1QTYMw/jNb37jlrgVFRUZkoxLLrnEMAyjyQT5s88+MyQZYWFhxu7duxttZ926dc4zcD/99JOz/He/+50hyRgzZozH/l1zzTUeE+Q5c+Y4z1h6cuDAAaNz586G1Wp1O2vdkglyWVmZ8fbbbxudO3d2niW22+2GYfzfwcJ7773nsb133nnHkGRkZ2e7lTfsj9/+9rdN9uV4CfKPP/5omM1mw2QyNUrmDMMwdu7c6Tyb+/nnnzvLXROdY5OBY7drMpmMb775ptHyP/zhD84zhnv27Gm0fOTIkYYk4/XXX28ytmNt27bNkGT079+/0bKG/v7lL39ptKy6utp5VrukpMRZvmHDBmdyeWzy5YndbneedVy3bp3HOs8++6whyXjggQe8imn8+PGGJOOCCy7wqv6xhg0b5vzriidXXXWVIckYN26cW3lDgnz99dc3WqeiosL5fj744IONlhcUFDj/+uDK9XPj6YxvdXW1ER8fb0gy3nrrLa9jfOSRRwxJxuzZs93KG35/27VrZ2zfvr3J9T0lyL///e8NSR7/quDJHXfcYUgyrr32Wo/LG/7Kc9lll7mVNyTIaWlpjRJxw/i//f/EE0941Q/AE65BBk6zY2/Wa3g90c15K1eulCRdccUV6tKlS6PlaWlpSklJkcPh0KpVqxqtd8stt3hsd+zYsR7L33//fUnSmDFjPC4PDw9Xenq66uvrW3TWjaFDhzqvb4yJidHNN9+svXv3ql+/flqyZInMZrNziq7Q0FCNHDnSYzsN10t+8cUXHpdfd911J9W/Tz/9VA6HQ3379lVycnKj5fHx8crMzJQkffLJJx7byM7OPu42unXrpvPOO69R+dlnny3p6L7u3Llzk8tLS0sbLbPb7crLy9OTTz6p3//+98rJydHtt9+up59+WpK0bdu2Jvvj6T0ODg5WYmKiJLldU79ixQpJ0pVXXqn4+Pgm22xQWFio0tJS2Ww2paWleaxzon3Zkurr6/X5559LUpPzXt9xxx2Smt6/WVlZjco6duyo6OjoJpcfb9818PS7Ghwc7Pwdbfhdd1VRUaE33nhDkydP1rhx43T77bfr9ttvd44RTe33vn37OvevtwYMGCDp6Ew0ixYt0sGDB49bv6G/J3qfP/vsM9nt9kbLr7rqKo/XQffq1UuSGt3rATQHt2cDp9nQoUPVs2dPvffee3rhhRf0xhtvKCIi4oQJW8Ngf7wbjmw2m77++mu3L4adO3ced72myouLiyVJt956q2699dbj9q2srOy4y5vDdR7k4OBgxcXF6eKLL3YmzpK0Y8cOGYahI0eOKDg4+KT6drIPRvF2P7jWddW5c2eFhYUddxvdunXzWB4eHn7c5R06dJCkRjfdfffddxo9erQ2b97c5Darqqqa3Z+IiIhG2/vxxx8lyesZDho+Z9u3bz/hgye8/ZzFxMRIOjqPdnNVVFQ442lqHx9v/0rH338VFRUelzfsu6ZuLouKilJUVJTHZQ39bPhdb/Df//3fuv/++3Xo0CGP60lN7/eT+f249dZb9eGHH+qtt95Sdna2LBaLevfurYsuukjXXXedLr30Urf6J/pdanifq6urVVFR0eigsDmfS6C5SJCB06zhDvGpU6dq7Nix2r17t+68806Fhoa2ddfcOBwOSU2fsXbVvXv3FtvusfMge9LQt/Dw8BOejW1KW73f3mzXbD7+H/dOtPxY1113nTZv3qyrrrpKkydPVu/evRUREaF27dqptrb2hAcZzd1eczTsy9jYWOeZ96Z06tTJqzYbzkTv2LFDFRUVzjO3p0tL7z9vGYbh/H9BQYHuuusuWSwW/elPf9LIkSPVrVs3hYWFyWQy6ZVXXtFdd93lto6rk/n9MJvNevPNN/Xoo4/q/fff1+eff67PP/9cc+bM0Zw5czRy5EgtXrxYFovlpGM8dntAayFBBtrA7bffrunTp2vZsmWSvJv7uOHP1Q1n3DxpWOb6p+34+Hht375dP/zwg/r06dNonaYekNC1a1cVFRXpjjvuOOnLEVpL165dJR092Jg3b95p/aI82f3QVoqKirRx40Z17txZixcvbjSv83fffdei22s4q9fU1GPHatiX0dHReu2111qkD0OHDlWHDh104MABvfHGG7r//vu9Xjc6OlrBwcGqqalRcXGxx8to2mL/7t+/X/v37/d4FrnhdzghIcFZ9u6778owDN1zzz2aPHlyo3Vaer+76t27t3r37q0HH3xQhmHo448/1s0336xly5bpjTfeUE5OjqT/G5uKi4s9XlLU8D6HhIQ4p3kEThcOv4A20K1bN11zzTWKjo7WBRdcoIyMjBOu03BWdcWKFdqzZ0+j5YWFhdqwYYPMZrMGDx7sLG+Y0/ett97y2O4bb7zhsXzEiBGSpHfeeeeEfTvd4uLilJycrAMHDjiveT1dBg8eLLPZrA0bNujrr79utPznn3929mno0KGntW+e/PLLL5KOvmeeHnry5ptvtuj2rrjiCknS//zP/xz3etoG/fv3V6dOnbRly5bjXgLSHBEREfrDH/4gSXriiSe0Y8eO49Y/ePCgCgsLJR19eEjDI8WbStgb7hs43ft3/vz5jcpqa2u1YMECSXL7y0vDfvf0153q6motXLiwdTp5DJPJpGHDhunmm2+WJG3YsMG5rKG/J3qfL774Yh7Yg9OOBBloI4sWLVJ5ebnXD0G46KKLlJGRoSNHjuiuu+5ye0hHeXm57rrrLknSjTfe6DwrJ0n33HOPLBaL3nnnHS1evNitzX/+859asmSJx+3deeed6t69u95991099NBDOnDgQKM6u3fv1n//93971f+W9tRTT0mScnJynGfiXRmGofz8fP3nP/9p0e1269ZN119/vQzD0F133aWKigrnskOHDunOO+9UdXW1Bg0apEGDBrXotk/GOeecI4vFom+++abRTVzLli3T888/36LbS01N1TXXXKMjR47ommuucT6VsEF9fb3+9a9/OX9u166dpk6dKsMwNHr0aK1evbpRm3a7XR9//LG+/PJLr/sxZcoUDRo0SPv379dFF13k8TNit9u1ePFipaWlud3Y+sADD0iS5syZo7y8PLd1XnvtNf3rX/9Su3btdO+993rdn5bw5JNPatOmTc6fHQ6HHnroIe3cuVNdu3Z1u9yo4Ua1119/3e13t7q6Wr///e9PeNBwMt544w0VFBQ0Kj9w4IDzs+easN97772yWq1asmRJowO1//znP3r55ZclSX/84x9bvK/AiXBIBviRt99+W5deeqmWLl2qnj17avDgwaqrq9Mnn3yiqqoq9evXT3/961/d1klNTdWMGTM0efJkXXvttcrIyJDNZtN3332nr776Svfff7/HJKl9+/Z6//33ddVVV+nZZ5/VK6+8ouTkZCUkJOjw4cP69ttvtXXrVnXu3Fnjxo07XW+B08iRIzVr1iw98MADuvrqq3XWWWfp3HPPVWRkpMrKyvT1119r7969euihh074dMLmmj17toqKipSfny+bzaahQ4fKarVq1apVKisrU8+ePZs8Y3+6derUSRMnTtSsWbM0bNgwXXzxxYqLi9O2bdu0fv165ebmOg82Wsqrr76qrKwsffnllzr77LM1aNAgxcXFaffu3frmm29UVlbmdu3rxIkTVVJSoj//+c+6+OKL1adPH5111lkKDQ3V7t27tWHDBu3fv19z5szRBRdc4FUfgoKC9MEHH+iOO+7QO++8o6uvvlpnnnmm0tLSFBERoYqKCn311Vf65ZdfFBwc7Haj2IgRI5zvy2WXXaYLL7xQ3bp1U1FRkdavXy+LxaKXXnrJ4yVLraVbt25KS0tTv379dMkllyg6OlpfffWVtm/frvbt2+vtt99WSEiIs35OTo5mzZqlwsJC9ezZUxdffLEsFos+++wzHTlyRPfee6/zaYMtZdGiRRo7dqzi4uKUmpqqM844Q/v27dPnn3+uyspKnXfeeW5jxfnnn6/Zs2drwoQJuvXWW/X8888rKSlJP/74o7744gsZhqFp06a1+O8v4JW2ml8O+LU4dh7kEzneg0IM4+h8qo888ojRq1cvIyQkxAgLCzP69u1rPPPMM8bhw4ebbHfp0qXGRRddZLRv394IDw83Bg0aZLz33ntuT+rypKqqynj22WeNgQMHGlFRUUa7du2MM8880+jfv7/x4IMPNpqMvzUeFHI833zzjXHnnXcaZ599tvP9SExMNDIzM42//OUvxq5du9zqN+yPYx9g4epEDwoxjKMPS5kxY4aRmppqhIWFGSEhIUavXr2MRx991OPTDE/0Pnuz3RO9tw0P75g6dapbucPhMObOnWukpaUZ4eHhRmRkpHHRRRcZ//znPw3D8Dyn7fHKGzTM++tpn9XU1Bhz5swxLr74YiMqKsoICgoyEhISjMsuu6zR3LsNPv/8c+M3v/mN0b17dyM4ONjo0KGDcc455xijRo0y/v73v3t8X72xZs0a48477zR69eplREREGFar1ejUqZMxePBg4+mnn25yvuZ///vfRlZWlhEdHW1YrVYjNjbWuP766438/Pxmvx+GceLPnqf32/VzU1dXZzz99NNGUlKSERwcbHTs2NHIzs42Nm/e7LG9srIy4/e//71hs9mM4OBgIy4uzrjllluM7777rsnPkre/v576+umnnxr33XefMWDAACM2NtYICgoyYmNjjYEDBxovvvii28ONXH355ZfGddddZ8TGxhpWq9WIjo42rrzyykYPCGnQMA/yq6++6nH5yY5BgCuTYTRxCysAAGhTP/zwg3r27Knu3bs3eUMtgJbHNcgAAACACxJkAAAAwAUJMgAAAOCCa5ABAAAAF5xBBgAAAFyQIAMAAAAueFBIC3E4HCotLVWHDh1kMpnaujsAAAA4hmEYOnDggOLi4mQ2N32emAS5hZSWlro93hcAAAC+6aefflJCQkKTy0mQW0iHDh0kHX3DIyIi2rg3CGT19fUqLCxU3759ZbXyKwzA/zGu4XSpqqpS165dnXlbU/gUtpCGyyoiIiJIkNGq6uvr1b59e0VERPBFAiAgMK7hdDvR5bDcpAf4GYvFouTkZFkslrbuCgC0CMY1+BoSZMAPBQUFtXUXAKBFMa7Bl5AgA37Gbrdr3bp1stvtbd0VAGgRjGvwNSTIAAAAgAsSZAAAAMAFCTIAAADgggQZ8DMWi0Xp6enc7Q0gYDCuwdeQIAN+qLa2tq27AAAtinENvoQEGfAzdrtdGzdu5G5vAAGDcQ2+hgQZAAAAcEGCDAAAALggQQb8EDeyAAg0jGvwJda27gCA5rFarerfv39bdwMAWgzjGnwNZ5ABP2MYhvbv3y/DMNq6KwDQIhjX4GtIkAE/Y7fbVVRUxN3eAAIG4xp8DQkyAAAA4IIEGQAAAHDBTXqAnzGZTAoNDZXJZGrrrgCAR4cPH1ZRUZHX9Q8dOqTVq1errq5O7du393q9pKQkhYWFnUwXgeMiQQb8jMViUUpKSlt3AwCaVFRUpLS0tFbfTkFBgfr169fq28GvDwky4GccDofKy8vVqVMnmc1cJQXA9yQlJamgoMDr+lu2bNGtt96q+fPnq3fv3s3aDtAaSJABP+NwOFRcXKyOHTuSIAM4rUpKpPJyb2qGSfL+zK7DUf+/r+c0az1vr+Lo1Enq1s3rZgESZAAAcGIlJVKvXoYOH26N+x+OpiNjx7ZOWhIWZmjrVhNJMrxGggwAAE6ovFw6fNike/+8TwmJ9S3adm1NtPbu+kid46MVFFzWom3vLLZq1oNnqLycs8jwHgky4GdMJpMiIyOZxQJAm0hIrFdin5ZNkKUgJfVruPa4pdsGmo8EGfAzFotFvXr1autuAAAQsLjDB/AzDodDO3fulMPhaOuuAAAQkEiQAT9DggwAQOsiQQYAAABckCADAAAALkiQAT9jNpsVExPDQ0IAAGglzGIB+Bmz2SybzdbW3QAAIGBxCgrwMw6HQ9u3b+cmPQAAWolPJsizZ89Wjx49FBISooyMDK1du7bJunV1dXriiSdks9kUEhKilJQUrVixwq3OnDlzlJycrIiICEVERGjgwIH697//7Vbnkksukclkcvs3fvz4VokPOBUOh0NlZWUkyAAAtBKfS5AXLFigSZMmaerUqVq/fr1SUlKUmZmpvXv3eqyfm5url19+WS+++KK2bNmi8ePHa/To0SosLHTWSUhI0DPPPKOCggKtW7dOl156qa655hpt3rzZra1x48bp559/dv579tlnWzVWAAAA+B6fS5BnzpypcePGKScnR71799ZLL72ksLAwzZs3z2P9+fPn69FHH1VWVpYSExM1YcIEZWVl6bnnnnPWGTlypLKysnT22WfrnHPO0dNPP63w8HB9+eWXbm2FhYUpNjbW+S8iIqJVYwUAAIDv8amb9Gpra1VQUKBHHnnEWWY2mzV8+HCtWbPG4zo1NTUKCQlxKwsNDdXq1as91rfb7Xr33Xd16NAhDRw40G3ZW2+9pTfffFOxsbEaOXKkHn/8cYWFhTW53ZqaGufPVVVVkqT6+nrV19c7+242m+VwONz+HN5QbrfbZRjGCcstFotMJpOzXdfyhpi8KbdarTIMw63cZDLJYrE06mNT5cTkGzHFxcXJ4XDIbrcHTEwnKicmYiKmto3JB8+pNYvdbld9feDvJ2I6fkzH1m+KTyXI5eXlstvt6tKli1t5ly5dVFRU5HGdzMxMzZw5U4MHD5bNZlNeXp4WLVrU6I355ptvNHDgQFVXVys8PFyLFy9W7969nctvvvlmde/eXXFxcdq4caMeeughbdu2TYsWLfK43RkzZmj69OmNygsLC9W+fXtJUkxMjGw2m3bs2KGysjJnnYSEBCUkJOjbb79VZWWlszwxMVGdO3fWpk2bdOTIEWd5UlKSoqKiVFhY6BZXcnKygoKCtG7dOrc+pKenq7a2Vhs3bnSWWSwW9e/fX5WVlW7vZWhoqFJSUlReXq7i4mJneWRkpHr16qXS0lLt3LnTWU5MvhNTaWlpwMUkBd5+IiZiCpSYpM7yZyUlJbLb9zh/DtT9REzHj8n1EtzjMRmu6XgbKy0tVXx8vL744gu3s7uTJ0/WqlWrlJ+f32idsrIyjRs3TsuWLZPJZJLNZtPw4cM1b948tzeytrZWJSUlqqys1Hvvvae///3vWrVqlVuS7Orjjz/WsGHD9P3333ucUsvTGeSuXbuqoqLCeWlGWx8lBeKRHzE5VF9fr++++05nn322LBZLQMQUiPuJmIgp0GLasMGstDTpzwvLlNjHu7NwvqB4s1UPZsdo7Vq7+vYN/P1ETMePad++fYqOjlZlZeVxL6X1qTPInTp1ksVi0Z49e9zK9+zZo9jYWI/rxMTEaMmSJaqurlZFRYXi4uL08MMP/+/R7v8JCgrSWWedJUlKS0vTV199pVmzZunll1/22G5GRoYkNZkgBwcHKzg4uFG51WqV1er+tjbs3GM17Cxvy49t92TKTSaTx/Km+tjccmI6PTEdOHBAZrPZ2YdAiOlUy4mJmJoqJ6aWi8mfWSwWeXqLA3E/EVPzyxv1z6tap0lQUJDS0tKUl5fnLHM4HMrLy2t0vfCxQkJCFB8fr/r6ei1cuFDXXHPNces7HA63M8DH2rBhgyTpzDPP9D4AAAAA+D2fOoMsSZMmTdLYsWOVnp6uAQMG6IUXXtChQ4eUk5MjSbrtttsUHx+vGTNmSJLy8/O1a9cupaamateuXZo2bZocDocmT57sbPORRx7RiBEj1K1bNx04cEBvv/22Vq5cqQ8++ECStH37dr399tvKyspSdHS0Nm7cqPvvv1+DBw9WcnLy6X8TAAAA0GZ8LkEeM2aMysrKNGXKFO3evVupqalasWKF88a9kpISt1Py1dXVys3NVXFxscLDw5WVlaX58+crKirKWWfv3r267bbb9PPPPysyMlLJycn64IMPdNlll0k6eub6o48+cibjXbt2VXZ2tnJzc09r7IA3zGazEhMTPf5pCgAAnDqfuknPn1VVVSkyMvKEF30DAOCP1q+XX9+kV1Ag9evX1r1BW/M2X+MUFOBn7Ha7vv7660Z36AIAgJZBggz4GcMwdOTIEfHHHwAAWgcJMgAAAOCCBBkAAABwQYIM+BmLxaKkpKSAnMgfAABf4HPTvAE4PpPJ5DaNIQAAaFmcQQb8TH19vb766qtGz58HAAAtgwQZ8ENM8QYAQOshQQYAAABckCADAAAALkiQAT9jsViUnJzMLBYAALQSEmTADwUFBbV1FwAACFgkyICfsdvtWrduHTfqAQDQSkiQAQAAABckyAAAAIALEmQAAADABQky4GcsFovS09OZxQIAgFZCggz4odra2rbuAgAAAYsEGfAzdrtdGzduZBYLAABaCQkyAAAA4IIEGQAAAHBBggz4IW7QAwCg9VjbugMAmsdqtap///5t3Q0AAAIWZ5ABP2MYhvbv3y/DMNq6KwAABCQSZMDP2O12FRUVMYsFAACthAQZAAAAcEGCDAAAALggQQb8jMlkUmhoqEwmU1t3BQCAgMQsFoCfsVgsSklJaetuAAAQsDiDDPgZh8OhvXv3yuFwtHVXAAAISCTIgJ9xOBwqLi4mQQYAoJWQIAMAAAAuSJABAAAAFyTIgJ8xmUyKjIxkFgsAAFoJs1gAfsZisahXr15t3Q0AAAIWZ5ABP+NwOLRz505u0gMAoJWQIAN+hgQZAIDWRYIMAAAAuOAaZKCNHT58WEVFRV7XP3jwoD755BPV1tYqPDzc6/WSkpIUFhZ2Ml0EAOBXhQQZaGNFRUVKS0tr9nrTpk1rVv2CggL169ev2dsBAODXhgQZaGNJSUkqKCjwuv7WrVt1yy236M0332zWbBZJSUkn0z0AAH51SJCBNhYWFtasM7sNN+ede+65nBEGAKAVcJMe4GcaEmRmsQAAoHWQIAMAAAAuSJABAAAAFyTIgJ8xm81urwAAoGX55Dfs7Nmz1aNHD4WEhCgjI0Nr165tsm5dXZ2eeOIJ2Ww2hYSEKCUlRStWrHCrM2fOHCUnJysiIkIREREaOHCg/v3vf7vVqa6u1t13363o6GiFh4crOztbe/bsaZX4gFNBggwAQOvyuW/YBQsWaNKkSZo6darWr1+vlJQUZWZmau/evR7r5+bm6uWXX9aLL76oLVu2aPz48Ro9erQKCwuddRISEvTMM8+ooKBA69at06WXXqprrrlGmzdvdta5//77tWzZMr377rtatWqVSktLde2117Z6vEBz2e12t1cAANCyfC5BnjlzpsaNG6ecnBz17t1bL730ksLCwjRv3jyP9efPn69HH31UWVlZSkxM1IQJE5SVlaXnnnvOWWfkyJHKysrS2WefrXPOOUdPP/20wsPD9eWXX0qSKisrNXfuXM2cOVOXXnqp0tLS9Oqrr+qLL75w1gF8hWEYbq8AAKBl+dQ8yLW1tSooKNAjjzziLDObzRo+fLjWrFnjcZ2amhqFhIS4lYWGhmr16tUe69vtdr377rs6dOiQBg4cKOnoE8bq6uo0fPhwZ72kpCR169ZNa9as0QUXXOBxuzU1Nc6fq6qqJEn19fWqr6939t1sNsvhcLhNydVQbrfb3ZKcpsotFotMJpOzXdfyhpi8KbdarTIMw63cZDLJYrE06mNT5cTkOzE5HA7Z7faAiul45cRETMTUtjH54Dm1ZrHb7aqvD/z9REzHj+nY+k3xqQS5vLxcdrtdXbp0cSvv0qWLioqKPK6TmZmpmTNnavDgwbLZbMrLy9OiRYsavTHffPONBg4cqOrqaoWHh2vx4sXq3bu3JGn37t0KCgpSVFRUo+3u3r3b43ZnzJih6dOnNyovLCxU+/btJUkxMTGy2WzasWOHysrKnHUSEhKUkJCgb7/9VpWVlc7yxMREde7cWZs2bdKRI0ec5UlJSYqKilJhYaFbXMnJyQoKCtK6devc+pCenq7a2lpt3LjRWWaxWNS/f39VVla6vZehoaFKSUlReXm5iouLneWRkZHq1auXSktLtXPnTmc5MbV9TA3lRUVFARNTIO4nYiKmQItJ6ix/VlJSIrv9/+4tCtT9REzHj8n1EtzjMRk+9Hfa0tJSxcfH64svvnCe3ZWkyZMna9WqVcrPz2+0TllZmcaNG6dly5bJZDLJZrNp+PDhmjdvntsbWVtbq5KSElVWVuq9997T3//+d61atUq9e/fW22+/rZycHLczwpI0YMAADR06VH/6058abdfTGeSuXbuqoqJCERERktr+KCkQj/yIyaGvvvpKF1xwgb788kulp6cHREyBuJ+IiZgCLaYNG8xKS5P+vLBMiX28OwvnC4o3W/VgdozWrrWrb9/A30/EdPyY9u3bp+joaFVWVjrzNU986gxyp06dZLFYGs0esWfPHsXGxnpcJyYmRkuWLFF1dbUqKioUFxenhx9++H+Pdv9PUFCQzjrrLElSWlqavvrqK82aNUsvv/yyYmNjVVtbq/3797udRT7edoODgxUcHNyo3Gq1ymp1f1sbdu6xGnaWt+XHtnsy5SaTyWN5U31sbjkxtX5M7dq1kyS1a9fO2Qd/jykQ9xMxEVMgxuTPLBaLPL3FgbifiKn55Y3651Wt0yQoKEhpaWnKy8tzljkcDuXl5bmdUfYkJCRE8fHxqq+v18KFC3XNNdcct77D4XCeAU5LS1O7du3ctrtt2zaVlJSccLvA6cYsFgAAtC6fOoMsSZMmTdLYsWOVnp6uAQMG6IUXXtChQ4eUk5MjSbrtttsUHx+vGTNmSJLy8/O1a9cupaamateuXZo2bZocDocmT57sbPORRx7RiBEj1K1bNx04cEBvv/22Vq5cqQ8++EDS0etk7rjjDk2aNEkdO3ZURESE7rnnHg0cONDjDXpAW2IWCwAAWpfPJchjxoxRWVmZpkyZot27dys1NVUrVqxw3rhXUlLidkq+urpaubm5Ki4uVnh4uLKysjR//ny3SyX27t2r2267TT///LMiIyOVnJysDz74QJdddpmzzvPPPy+z2azs7GzV1NQoMzNTf/vb305b3AAAAPANPnWTnj+rqqpSZGTkCS/6Bk7V2rVrlZGRofz8fA0YMKCtuwPgV2L9evn1TXoFBVK/fm3dG7Q1b/M1n7oGGcCJNdyoEIg30QAA4AtIkAE/YzKZ3F4BAEDL8rlrkAEcX8Ocj94+DQgAWsr9mqm7xv2XrO3auifeq6+TSvVHSZPauivwIyTIAADAKxGqUodffm7rbjRbhKraugvwMyTIAADAK1WK0IGOZ/rdGeSqX7h5Hs1DggwAALzyvCYp7r9v9btZLJ7PjtEtbd0R+BVu0gP8DLNYAADQukiQAQAAABckyICfsdvtbq8AAKBlkSADAAAALkiQAQAAABckyAAAAIALEmTAzzCLBQAArYsEGQAAAHBBggz4GWaxAACgdZEgAwAAAC5IkAEAAAAXJMgAAACACxJkwM9YrVa3VwAA0LJIkAE/YxiG2ysAAGhZJMiAn2EWCwAAWhcJMgAAAOCCBBkAAABwQYIM+BmTyeT2CgAAWhYJMuBnLBaL2ysAAGhZJMiAn3E4HG6vAACgZZEgA36GBBkAgNZFggwAAAC4IEEGAAAAXJAgA36GWSwAAGhd1rbuABCoSkqk8vKWb/fbby3O19aYyKJTJ6lbt5ZvFwAAf0GCDLSCkhKpVy9Dhw+33lneW25pnXbDwgxt3WoiSQYA/GqRIAOtoLxcOnzYpHv/vE8JifUt2nZtTbT27vpIneOjFRRc1qJt7yy2ataDZ6i8nLPIAIBfLxJkoBUlJNYrsU/LJshSkJL69f7f/7d02wAAgJv0AAAAABckyAAAAIALEmQAAADABQkyAAAA4IIEGQAAAHBBggwAAAC4IEEGAAAAXJAgAwAAAC5IkAEAAAAXJMgAAACACxJkAAAAwAUJMgAAAODCJxPk2bNnq0ePHgoJCVFGRobWrl3bZN26ujo98cQTstlsCgkJUUpKilasWOFWZ8aMGerfv786dOigzp07a9SoUdq2bZtbnUsuuUQmk8nt3/jx41slPgAAAPgun0uQFyxYoEmTJmnq1Klav369UlJSlJmZqb1793qsn5ubq5dfflkvvviitmzZovHjx2v06NEqLCx01lm1apXuvvtuffnll/rwww9VV1enyy+/XIcOHXJra9y4cfr555+d/5599tlWjRUAAAC+x+cS5JkzZ2rcuHHKyclR79699dJLLyksLEzz5s3zWH/+/Pl69NFHlZWVpcTERE2YMEFZWVl67rnnnHVWrFih22+/XX369FFKSopee+01lZSUqKCgwK2tsLAwxcbGOv9FRES0aqwAAADwPda27oCr2tpaFRQU6JFHHnGWmc1mDR8+XGvWrPG4Tk1NjUJCQtzKQkNDtXr16ia3U1lZKUnq2LGjW/lbb72lN998U7GxsRo5cqQef/xxhYWFNbndmpoa589VVVWSpPr6etXX1zv7bjab5XA45HA43GIym82y2+0yDOOE5RaLRSaTydmua7kk2e12r8qtVqsMw3ArN5lMslgsjfrYVDkxeRfT0bB86terWRpiCPT9REzEREzex+SD59SaxW63q74+8PcTMR0/pmPrN8WnvsHLy8tlt9vVpUsXt/IuXbqoqKjI4zqZmZmaOXOmBg8eLJvNpry8PC1atKjRG9PA4XDovvvu04UXXqjzzjvPWX7zzTere/fuiouL08aNG/XQQw9p27ZtWrRokcd2ZsyYoenTpzcqLywsVPv27SVJMTExstls2rFjh8rKypx1EhISlJCQoG+//daZrEtSYmKiOnfurE2bNunIkSPO8qSkJEVFRamwsNAtruTkZAUFBWndunVufUhPT1dtba02btzoLLNYLOrfv78qKyvd3svQ0FClpKSovLxcxcXFzvLIyEj16tVLpaWl2rlzp7OcmLyLaevWYEnJ8ldbt26Rw3E44PcTMRETMXkfk9RZ/qykpER2+x7nz4G6n4jp+DG5XoJ7PCbDNR1vY6WlpYqPj9cXX3yhgQMHOssnT56sVatWKT8/v9E6ZWVlGjdunJYtWyaTySSbzabhw4dr3rx5bm9kgwkTJujf//63Vq9erYSEhCb78vHHH2vYsGH6/vvvZbPZGi33dAa5a9euqqiocF6a0dZHSYF45OcvMa1fL2VkWPXnhWVK7OPd0aovKN5s1YPZMcrPr1e/foG/n4iJmIjJ+5g2bDArLU1+O66tXWtX376Bv5+I6fgx7du3T9HR0aqsrDzupbQ+dQa5U6dOslgs2rNnj1v5nj17FBsb63GdmJgYLVmyRNXV1aqoqFBcXJwefvjh/z3adTdx4kQtX75cn3766XGTY0nKyMiQpCYT5ODgYAUHBzcqt1qtslrd39aGnXushp3lbfmx7Z5Muclk8ljeVB+bW05MDZ8Bj4v8xrExBOp+OtVyYiIm6dcVkz+zWCwex+ZA3E/E1PzyRv3zqtZpEhQUpLS0NOXl5TnLHA6H8vLy3M4oexISEqL4+HjV19dr4cKFuuaaa5zLDMPQxIkTtXjxYn388cfq2bPnCfuyYcMGSdKZZ555csEAAADAL/ncea5JkyZp7NixSk9P14ABA/TCCy/o0KFDysnJkSTddtttio+P14wZMyRJ+fn52rVrl1JTU7Vr1y5NmzZNDodDkydPdrZ599136+2339bSpUvVoUMH7d69W9LR62NCQ0O1fft2vf3228rKylJ0dLQ2btyo+++/X4MHD1Zysv9eRwoAAIDm87kEecyYMSorK9OUKVO0e/dupaamasWKFc4b90pKStxOyVdXVys3N1fFxcUKDw9XVlaW5s+fr6ioKGedOXPmSDr6MBBXr776qm6//XYFBQXpo48+cibjXbt2VXZ2tnJzc1s9XgAAAPgWn0uQpaPXCk+cONHjspUrV7r9PGTIEG3ZsuW47Z3oPsSuXbtq1apVzeojAAAAApNPXYMMAAAAtDUSZAAAAMAFCTIAAADgggQZAAAAcEGCDAAAALggQQYAAABckCADAAAALkiQAQAAABckyAAAAIALEmQAAADABQkyAAAA4IIEGQAAAHBBggwAAAC4IEEGAAAAXJAgAwAAAC5IkAEAAAAXJMgAAACACxJkAAAAwAUJMgAAAOCCBBkAAABwQYIMAAAAuCBBBgAAAFyQIAMAAAAuSJABAAAAFyTIAAAAgAsSZAAAAMAFCTIAAADgggQZAAAAcGFt6w4Agep+zdRd4/5L1nZt3RPv1ddJpfqjpElt3RUAANoMCTLQSiJUpQ6//NzW3Wi2CFW1dRcAAGhTJMhAK6lShA50PNPvziBX/RLR1t0AAKBNkSADreR5TVLcf9+qxD71bd0VrxVvtur57Bjd0tYdAQCgDXGTHgAAAOCCBBkAAABwQYIMAAAAuCBBBgAAAFyQIAMAAAAuTjpBLikp0fjx43XuueeqY8eO+vTTTyVJ5eXl+sMf/qDCwsIW6yQAAABwupzUNG9btmzRxRdfLIfDoYyMDH3//feqrz86lVWnTp20evVqHTp0SHPnzm3RzgIAAACt7aQS5MmTJysqKkpffvmlTCaTOnfu7Lb8yiuv1IIFC1qkgwAAAMDpdFKXWHz66aeaMGGCYmJiZDKZGi3v1q2bdu3adcqdAwAAAE63k0qQHQ6HwsLCmlxeVlam4ODgk+4UAAAA0FZOKkHu16+f3n//fY/L6uvr9c9//lMXXHDBKXUMAAAAaAsnlSA/8sgjWrFihSZMmKBNmzZJkvbs2aOPPvpIl19+ubZu3aqHH364RTsKAAAAnA4ndZPeiBEj9Nprr+nee+/VK6+8Ikm65ZZbZBiGIiIi9MYbb2jw4MEt2lEAAADgdDjpeZBvvfVW/fTTT1q4cKH+9Kc/6f/9v/+nd955Rz/99JNuuummU+rU7Nmz1aNHD4WEhCgjI0Nr165tsm5dXZ2eeOIJ2Ww2hYSEKCUlRStWrHCrM2PGDPXv318dOnRQ586dNWrUKG3bts2tTnV1te6++25FR0crPDxc2dnZ2rNnzynFAQAAAP/T7AT58OHDio6O1p///Ge1b99eo0aN0oMPPqiHHnpI1113nTp06HBKHVqwYIEmTZqkqVOnav369UpJSVFmZqb27t3rsX5ubq5efvllvfjii9qyZYvGjx+v0aNHuz2oZNWqVbr77rv15Zdf6sMPP1RdXZ0uv/xyHTp0yFnn/vvv17Jly/Tuu+9q1apVKi0t1bXXXntKsQAAAMD/NDtBDgsLk9VqVfv27VujP5o5c6bGjRunnJwc9e7dWy+99JLCwsI0b948j/Xnz5+vRx99VFlZWUpMTNSECROUlZWl5557zllnxYoVuv3229WnTx+lpKTotddeU0lJiQoKCiRJlZWVmjt3rmbOnKlLL71UaWlpevXVV/XFF1/oyy+/bJU4AQAA4JtO6hKL7OxsvffeezIMo0U7U1tbq4KCAg0fPtxZZjabNXz4cK1Zs8bjOjU1NQoJCXErCw0N1erVq5vcTmVlpSSpY8eOkqSCggLV1dW5bTcpKUndunVrcrsAAAAITCd1k96NN96o3//+9xo6dKjGjRunHj16KDQ0tFG9fv36Navd8vJy2e12denSxa28S5cuKioq8rhOZmamZs6cqcGDB8tmsykvL0+LFi2S3W73WN/hcOi+++7ThRdeqPPOO0+StHv3bgUFBSkqKqrRdnfv3u2xnZqaGtXU1Dh/rqqqknR0mruGx26bzWaZzWY5HA45HA5n3YZyu93udpDRVLnFYpHJZHK261ouqVGsTZVbrVYZhuFWbjKZZLFYGvWxqXJi8i6mo2Gd1K+XT2iIIdD3EzEREzF5H9Mp3LbkE+x2u+rrA38/EdPxYzq2flNO6hv8kksucf7/s88+a7TcMAyZTKYmk9SWNGvWLI0bN05JSUkymUyy2WzKyclp8pKMu+++W5s2bTruGWZvzJgxQ9OnT29UXlhY6Lz8JCYmRjabTTt27FBZWZmzTkJCghISEvTtt986z2ZLUmJiojp37qxNmzbpyJEjzvKkpCRFRUWpsLDQ7T1NTk5WUFCQ1q1b59aH9PR01dbWauPGjc4yi8Wi/v37q7Ky0u1gIzQ0VCkpKSovL1dxcbGzPDIyUr169VJpaal27tzpLCcm72LaujVYUrL81datW+RwHA74/URMxERM3sckdZY/Kykpkd3+fzffB+p+Iqbjx+R6j9rxmIyTuE7i9ddf96re2LFjm9VubW2twsLC9N5772nUqFFu7ezfv19Lly5tct3q6mpVVFQoLi5ODz/8sJYvX67Nmze71Zk4caKWLl2qTz/9VD179nSWf/zxxxo2bJj27dvndha5e/fuuu+++3T//fc32p6nM8hdu3ZVRUWFIiIiJLX9UVIgHvn5S0zr10sZGVb9eWGZEvt4d7TqC4o3W/Vgdozy8+vVr1/g7ydiIiZi8j6mDRvMSkuT345ra9fa1bdv4O8nYjp+TPv27VN0dLQqKyud+ZonJ3UGubmJr7eCgoKUlpamvLw8Z4LscDiUl5eniRMnHnfdkJAQxcfHq66uTgsXLtQNN9zgXGYYhu655x4tXrxYK1eudEuOJSktLU3t2rVTXl6esrOzJUnbtm1TSUmJBg4c6HF7wcHBHh+nbbVaZbW6v60NO/dYDTvL2/Jj2z2ZcpPJ5LG8qT42t5yYGj4DHhf5jWNjCNT9dKrlxERM0q8rJn9msVg8js2BuJ+Iqfnljep5Ves4Dh48qJ9++kmS1LVrV4WHh59Se5MmTdLYsWOVnp6uAQMG6IUXXtChQ4eUk5MjSbrtttsUHx+vGTNmSJLy8/O1a9cupaamateuXZo2bZocDocmT57sbPPuu+/W22+/raVLl6pDhw7O64ojIyMVGhqqyMhI3XHHHZo0aZI6duyoiIgI3XPPPRo4cCCPzAYAAPiVOekE+auvvtLkyZO1evVq5ylys9msiy++WM8++6zS09NPqt0xY8aorKxMU6ZM0e7du5WamqoVK1Y4b9wrKSlxO+Korq5Wbm6uiouLFR4erqysLM2fP9/tUok5c+ZIcr92WpJeffVV3X777ZKk559/XmazWdnZ2aqpqVFmZqb+9re/nVQMAAAA8F8nlSDn5+frkksuUVBQkH73u9+pV69ekqStW7fqH//4hwYPHqyVK1dqwIABJ9WpiRMnNnlJxcqVK91+HjJkiLZs2XLc9ry5zDokJESzZ8/W7Nmzve4nAAAAAs9JJciPPfaY4uPjtXr1asXGxrotmzZtmi688EI99thj+vDDD1ukkwAAAMDpclKTGubn5+uuu+5qlBxLR+cOvvPOO3kCHQAAAPzSSSXIZrP5uBMt2+12j3cmAgAAAL7upLLYQYMGafbs2frxxx8bLSspKdHf/vY3XXjhhafcOQAAAOB0O6lrkP/f//t/Gjx4sJKSkjR69Gidc845ko7OHbx06VJZrVbnNGwAAACAPzmpBLlv377Kz8/XY489pn/96186fPiwJCksLExXXHGFnnrqKfXu3btFOwoAAACcDic9D3Lv3r21ePFiORwO57O0Y2JiuPYYAAAAfu2Un6RnNpudD/EAAAAA/N1Jne7Nzc1Vampqk8v79u2r6dOnn2yfAAAAgDZzUgnye++9pxEjRjS5PCsrSwsWLDjpTgEAAABt5aQS5JKSEtlstiaX9+zZ0+MUcAAAAICvO6kEOTw8/LgJ8I4dOxQSEnLSnQIAAADaykklyJdccolefvll7dq1q9Gyn376Sa+88oqGDh16yp0DAAAATreTmsXiySef1IABA9SnTx/dcccd6tOnjyRp06ZNmjdvngzD0JNPPtmiHQUAAABOh5NKkM8991x99tlnuueee/T888+7LRs8eLD+8pe/qFevXi3SQQAAAOB0Oul5kJOTk7Vq1SqVl5eruLhYkpSYmKhOnTq1WOcAAACA0+2UHxTSqVMnkmIAAAAEDK9v0tu9e7c+/fRTHTx40K28rq5OU6ZMkc1mU1hYmPr166d//etfLd5RAAAA4HTwOkF+5plndP311ysoKMit/IEHHtBTTz2lffv2qU+fPtq2bZuys7P16aeftnhnAQAAgNbmdYK8atUqjRw50i1BLisr09/+9jf17t1bxcXF+uqrr7RlyxbFxMToueeea5UOAwAAAK3J6wT5p59+ck7n1mD58uVyOBz64x//qKioKElS9+7dlZOTo/z8/BbtKAAAAHA6eJ0gV1dXKzw83K3ss88+k8lk0rBhw9zKbTab9u3b1zI9BAAAAE4jrxPknj17asOGDW5ln3zyibp3766uXbu6lR88eFAdO3ZskQ4CAAAAp5PXCfK1116r119/XQsWLNBPP/2kp59+Wj/++KNuuOGGRnW//PJLJSYmtmhHAQAAgNPB63mQJ0+erGXLlummm26SyWSSYRg699xz9dhjj7nVq6io0L/+9S89+OCDLd5ZAAAAoLV5nSC3b99ea9eu1eLFi1VcXKzu3btr1KhRCgkJcau3a9cuTZ8+Xdddd12LdxYAALStncWn/IyxRmprDmvvru/VOf4sBQWHtWjbrdFfBL5mfWqsVquuv/7649ZJTk5WcnLyKXUKAAD4lk6dpLAwQ7MePKMVWl8vabikAkndW7z1sDBDnTqZWrxdBC4OqwAAwAl16yZt3WpSeXnLt71pU73GjpVef71e553X8u136mRSt24t3y4CFwkyAADwSrduapVE0+E4OmdA795m9evX8u0DzeX1LBYAAACtwWw2u70CbY1PIgAAaFMOh8PtFWhrJMgAAKBNkSDD15AgAwAAAC5aJUFevny5fvvb37ZG0wAAAECrapUE+euvv9brr7/eGk0DAIAAw0168DV8EgEAQJsiQYav8Xoe5MTERK8braysPKnOAACAXx+73e72CrQ1rxPkkpISxcfHe/UY6e+//1779+8/lX4BAIBfCcMw3F6BtuZ1gtyrVy9FRUVp2bJlJ6z79NNPa8qUKafUMQAAAKAteH2xz4ABA7R+/Xr+/AEAAICA5vUZ5BtvvFEOh0NlZWWKjY09bt2rr75aCQkJp9w5AAAQ+LhJD77G6wT5sssu02WXXeZV3fPPP1/nn3/+SXcKAAD8epAgw9fwSQQAAG2KWSzga7xOkB999FFt3LixNfsCAAB+hZjFAr7G6wT5mWee0aZNm5w/V1RUyGKx6OOPP26VjgEAAABt4ZQuseBIDwAAAIHG565Bnj17tnr06KGQkBBlZGRo7dq1Tdatq6vTE088IZvNppCQEKWkpGjFihVudT799FONHDlScXFxMplMWrJkSaN2br/9dplMJrd/V1xxRUuHBgAAPLBYLG6vQFvzqQR5wYIFmjRpkqZOnar169crJSVFmZmZ2rt3r8f6ubm5evnll/Xiiy9qy5YtGj9+vEaPHq3CwkJnnUOHDiklJUWzZ88+7ravuOIK/fzzz85///jHP1o0NgAA4JnJZHJ7Bdqa19O8SdIPP/yg9evXS5IqKyslSd99952ioqI81u/Xr1+zOjNz5kyNGzdOOTk5kqSXXnpJ77//vubNm6eHH364Uf358+frscceU1ZWliRpwoQJ+uijj/Tcc8/pzTfflCSNGDFCI0aMOOG2g4ODTzi/MwAAaHn19fVur0Bba1aC/Pjjj+vxxx93K/v973/fqJ5hGDKZTM2arqW2tlYFBQV65JFHnGVms1nDhw/XmjVrPK5TU1OjkJAQt7LQ0FCtXr3a6+02WLlypTp37qwzzjhDl156qZ566ilFR0c3ux0AAAD4N68T5FdffbU1+6Hy8nLZ7XZ16dLFrbxLly4qKiryuE5mZqZmzpypwYMHy2azKS8vT4sWLWr2PIpXXHGFrr32WvXs2VPbt2/Xo48+qhEjRmjNmjVNXg9VU1Ojmpoa589VVVWSjh79NhwBm81mmc1mORwOORwOZ92Gcrvd7najY1PlFotFJpOp0ZF1Q9+OjbepcqvVKsMw3MpNJpMsFkujPjZVTkzexXQ0rGYdf/qUhhgCfT8REzERk2/E1MDhcDjb8veYAnE/BUJM3v6Vwutv8LFjx3pb9bSZNWuWxo0bp6SkJJlMJtlsNuXk5GjevHnNaufGG290/v/8889XcnKybDabVq5cqWHDhnlcZ8aMGZo+fXqj8sLCQrVv316SFBMTI5vNph07dqisrMxZJyEhQQkJCfr222+dl6pIUmJiojp37qxNmzbpyJEjzvKkpCRFRUWpsLDQbYcnJycrKChI69atc+tDenq6amtr3eattlgs6t+/vyorK90OOEJDQ5WSkqLy8nIVFxc7yyMjI9WrVy+VlpZq586dznJi8i6mrVuDJSXLX23dukUOx+GA30/EREzE5BsxNQikmAJxPwVCTK73qR2PyfCRudpqa2sVFham9957T6NGjXKWjx07Vvv379fSpUubXLe6uloVFRWKi4vTww8/rOXLl2vz5s2N6plMJi1evNit/abExMToqaee0l133eVxuaczyF27dlVFRYUiIiIktf1RUiAe+flLTOvXSxkZVv15YZkS+/jPNXXFm616MDtG+fn16tcv8PcTMRETMflGTF9//bXS09OVn5/vvH/J32MKxP0UCDHt27dP0dHRqqysdOZrnvjM34CDgoKUlpamvLw8ZwLrcDiUl5eniRMnHnfdkJAQxcfHq66uTgsXLtQNN9xwSn3ZuXOnKioqdOaZZzZZJzg4WMHBwY3KrVarrFb3t7Vh5x6rqcs3mio/tt2TKTeZTB7Lm+pjc8uJqeEz4HGR3zg2hkDdT6daTkzEJBFTU308mXKLxeL1d6g/xBSI+ykQY/JYz6tap8mkSZM0duxYpaena8CAAXrhhRd06NAh56wWt912m+Lj4zVjxgxJUn5+vnbt2qXU1FTt2rVL06ZNk8Ph0OTJk51tHjx4UN9//73z5x07dmjDhg3q2LGjunXrpoMHD2r69OnKzs5WbGystm/frsmTJ+uss85SZmbm6X0DEHB2Frf8r1htzWHt3fW9OsefpaDgsBZtuzX6CwAn0nC2r7n3EAGtxae+DceMGaOysjJNmTJFu3fvVmpqqlasWOG8ca+kpMTtaKO6ulq5ubkqLi5WeHi4srKyNH/+fLdp59atW6ehQ4c6f540aZKko5duvPbaa7JYLNq4caNef/117d+/X3Fxcbr88sv15JNPejxDDHijUycpLMzQrAfPaIXW10saLqlAUvcWbz0szFCnTsxFCgD49fKZa5D9XVVVlSIjI094TQt+PUpKpPLylm9306a1Gjs2Q6+/nq/zzhvQ4u136iR169bizQJAk9auXauMjAzl5+drwICWH9eABt7maz51BhkIJN26tU6i2XA/QlKS1Mxn8QAAAC/41KOmAZxYw40KTd2wAAD+hnENvoYEGQAAAHBBggz4Ge72BhBoGNfga0iQAQAAABckyAAAAIALEmQAAADABQky4GcaHpPp7eMyAcDXMa7B15AgA36m4dk+POMHQKBgXIOvIUEG/Ax3ewMINIxr8DUkyAAAAIALEmQAAADABQky4GdMJpPbKwD4O8Y1+BoSZMDPWCwWt1cA8HeMa/A1JMiAn3E4HG6vAODvGNfga0iQAT/DFwmAQMO4Bl9DggwAAAC4IEEGAAAAXJAgA36Gu70BBBrGNfgaEmTAz3C3N4BAw7gGX0OCDPgZbmYBEGgY1+BrSJABP8MXCYBAw7gGX0OCDAAAALggQQYAAABckCADfsZsNru9AoC/Y1yDr+GTCPgZvkgABBrGNfgaPomAn+FmFgCBhnENvoYEGfAzfJEACDSMa/A1JMgAAACACxJkAAAAwAUJMuBnuJkFQKBhXIOv4ZMI+Bm+SAAEGsY1+Bo+iYCfsdvtbq8A4O8Y1+BrSJABP2MYhtsrAPg7xjX4GhJkAAAAwAUJMgAAAOCCBBnwM9zMAiDQMK7B1/BJBPwMXyQAAg3jGnwNn0TAz3C3N4BAw7gGX0OCDPgZ7vYGEGgY1+BrSJABAAAAFyTIAAAAgAsSZMDPWCwWt1cA8HeMa/A1JMiAnzGZTG6vAODvGNfga0iQAT9TX1/v9goA/o5xDb6GBBkAAABw4XMJ8uzZs9WjRw+FhIQoIyNDa9eubbJuXV2dnnjiCdlsNoWEhCglJUUrVqxwq/Ppp59q5MiRiouLk8lk0pIlSxq1YxiGpkyZojPPPFOhoaEaPny4vvvuu5YODQAAAH7ApxLkBQsWaNKkSZo6darWr1+vlJQUZWZmau/evR7r5+bm6uWXX9aLL76oLVu2aPz48Ro9erQKCwuddQ4dOqSUlBTNnj27ye0+++yz+stf/qKXXnpJ+fn5at++vTIzM1VdXd3iMQIAAMC3+VSCPHPmTI0bN045OTnq3bu3XnrpJYWFhWnevHke68+fP1+PPvqosrKylJiYqAkTJigrK0vPPfecs86IESP01FNPafTo0R7bMAxDL7zwgnJzc3XNNdcoOTlZb7zxhkpLSz2ebQbaGnd7Awg0jGvwNT6TINfW1qqgoEDDhw93lpnNZg0fPlxr1qzxuE5NTY1CQkLcykJDQ7V69Wqvt7tjxw7t3r3bbbuRkZHKyMhocrsAAAAIXNa27kCD8vJy2e12denSxa28S5cuKioq8rhOZmamZs6cqcGDB8tmsykvL0+LFi1q1rPcd+/e7dzOsdttWOZJTU2NampqnD9XVVVJOnoHbsNduGazWWazWQ6HQw6Hw1m3odxut7s9VrOpcovFIpPJ1Oju3oYj7WPjbarcarXKMAy3cpPJJIvF0qiPTZUTU9vHVFdXJ+noNfh2uz0gYgrE/URMxERM3sfU8HNdXZ2zLX+PKRD3UyDE5O1MKT6TIJ+MWbNmady4cUpKSpLJZJLNZlNOTk6Tl2S0pBkzZmj69OmNygsLC9W+fXtJUkxMjGw2m3bs2KGysjJnnYSEBCUkJOjbb79VZWWlszwxMVGdO3fWpk2bdOTIEWd5UlKSoqKiVFhY6LbDk5OTFRQUpHXr1rn1IT09XbW1tdq4caOzzGKxqH///qqsrHQ74AgNDVVKSorKy8tVXFzsLI+MjFSvXr1UWlqqnTt3OsuJqe1jaigvKioKmJgCcT8REzERk/cxNQikmAJxPwVCTK73qR2PyXBNx9tQbW2twsLC9N5772nUqFHO8rFjx2r//v1aunRpk+tWV1eroqJCcXFxevjhh7V8+XJt3ry5UT2TyaTFixe7tV9cXCybzabCwkKlpqY6y4cMGaLU1FTNmjXL4zY9nUHu2rWrKioqFBERIantj5IC8ciPmBxau3atBg4cqDVr1qh///4BEVMg7idiIiZi8j6m9evXOy9tTE9PD4iYAnE/BUJM+/btU3R0tCorK535mic+cwY5KChIaWlpysvLcyawDodDeXl5mjhx4nHXDQkJUXx8vOrq6rRw4ULdcMMNXm+3Z8+eio2NVV5enjNBrqqqUn5+viZMmNDkesHBwQoODm5UbrVaZbW6v60NO/dYTd2M0FT5se2eTLnJZPJY3lQfm1tOTKcvJrPZ7OxDoMR0KuXERExNlROTf8TU0B9vv0P9IaZA3E+BGJPHel7VOk0mTZqksWPHKj09XQMGDNALL7ygQ4cOKScnR5J02223KT4+XjNmzJAk5efna9euXUpNTdWuXbs0bdo0ORwOTZ482dnmwYMH9f333zt/3rFjhzZs2KCOHTuqW7duMplMuu+++/TUU0/p7LPPVs+ePfX4448rLi7O7Uwz4CsaBommBgsA8DeMa/A1PpUgjxkzRmVlZZoyZYp2796t1NRUrVixwnkDXUlJidvRRnV1tXJzc1VcXKzw8HBlZWVp/vz5ioqKctZZt26dhg4d6vx50qRJko5euvHaa69JkiZPnqxDhw7pzjvv1P79+3XRRRdpxYoVjWbIAAAAQODzmWuQ/V1VVZUiIyNPeE0LcKrWrl2rjIwM5efna8CAAW3dHQA4ZYxrOF28zdd8Zh5kAAAAwBeQIAMAAAAuSJABAAAAFyTIgJ9pmKLG26lqAMDXMa7B15AgA36m4b5a7q8FECgY1+BrSJABP9PwdKBjnxIEAP6KcQ2+hgQZAAAAcEGCDAAAALggQQb8jMlkcnsFAH/HuAZfQ4IM+BmLxeL2CgD+jnENvoYEGfAzDofD7RUA/B3jGnwNCTLgZ/giARBoGNfga0iQAQAAABckyAAAAIALEmTAz3C3N4BAw7gGX0OCDPgZ7vYGEGgY1+BrSJABP8PNLAACDeMafA0JMuBn+CIBEGgY1+BrSJABAAAAFyTIAAAAgAsSZMDPmM1mt1cA8HeMa/A1fBIBP8MXCYBAw7gGX8MnEfAz3MwCINAwrsHXkCADfoYvEgCBhnENvoYEGQAAAHBBggwAAAC4IEEG/Aw3swAINIxr8DV8EgE/wxcJgEDDuAZfwycR8DN2u93tFQD8HeMafA0JMuBnDMNwewUAf8e4Bl9DggwAAAC4IEEGAAAAXJAgA36Gm1kABBrGNfgaPomAn+GLBECgYVyDr+GTCPgZ7vYGEGgY1+BrSJABP8Pd3gACDeMafA0JMgAAAOCCBBkAAABwQYIM+BmLxeL2CgD+jnENvoYEGfAzJpPJ7RUA/B3jGnwNCTLgZ+rr691eAcDfMa7B15AgAwAAAC5IkAEAAAAXJMgAAACACxJkwM9wtzeAQMO4Bl9DggwAAAC48MkEefbs2erRo4dCQkKUkZGhtWvXNlm3rq5OTzzxhGw2m0JCQpSSkqIVK1Y0u81LLrlEJpPJ7d/48eNbPDbgVNntdrdXAPB3jGvwNT6XIC9YsECTJk3S1KlTtX79eqWkpCgzM1N79+71WD83N1cvv/yyXnzxRW3ZskXjx4/X6NGjVVhY2Ow2x40bp59//tn579lnn23VWAEAAOB7fC5BnjlzpsaNG6ecnBz17t1bL730ksLCwjRv3jyP9efPn69HH31UWVlZSkxM1IQJE5SVlaXnnnuu2W2GhYUpNjbW+S8iIqJVYwUAAIDv8akEuba2VgUFBRo+fLizzGw2a/jw4VqzZo3HdWpqahQSEuJWFhoaqtWrVze7zbfeekudOnXSeeedp0ceeUSHDx9uqdAAAADgJ6xt3QFX5eXlstvt6tKli1t5ly5dVFRU5HGdzMxMzZw5U4MHD5bNZlNeXp4WLVrkvI7J2zZvvvlmde/eXXFxcdq4caMeeughbdu2TYsWLfK43ZqaGtXU1Dh/rqqqknT0KUANTwIym80ym81yOBxyOBzOug3ldrtdhmGcsNxischkMjV6wlDD3b7HXrPVVLnVapVhGG7lJpNJFoulUR+bKiemto/Jld1uD4iYAnE/ERMxEZP3MbnOXtHQlr/HFIj7KRBi8vZpjT6VIJ+MWbNmady4cUpKSpLJZJLNZlNOTk6Tl2Q05c4773T+//zzz9eZZ56pYcOGafv27bLZbI3qz5gxQ9OnT29UXlhYqPbt20uSYmJiZLPZtGPHDpWVlTnrJCQkKCEhQd9++60qKyud5YmJiercubM2bdqkI0eOOMuTkpIUFRWlwsJCtx2enJysoKAgrVu3zq0P6enpqq2t1caNG51lFotF/fv3V2VlpduBQWhoqFJSUlReXq7i4mJneWRkpHr16qXS0lLt3LnTWU5MbR/T1q1bJUlbt25Vhw4dAiKmQNxPxERMxOR9TGbz0T9ob9261Zk0+XtMgbifAiEm13vUjsdkuKbjbay2tlZhYWF67733NGrUKGf52LFjtX//fi1durTJdaurq1VRUaG4uDg9/PDDWr58uTZv3nzSbR46dEjh4eFasWKFMjMzGy33dAa5a9euqqiocF673NZHSYF45EdMDq1du1YDBw7UmjVr1L9//4CIKRD3EzEREzF5H9P69euVkZGhNWvWKD09PSBiCsT9FAgx7du3T9HR0aqsrDzuvWY+dQY5KChIaWlpysvLcyazDodDeXl5mjhx4nHXDQkJUXx8vOrq6rRw4ULdcMMNp9Tmhg0bJElnnnmmx+XBwcEKDg5uVG61WmW1ur+tDTv3WK5/UvKm/Nh2T6bcZDJ5LG+qj80tJ6bTF5PZbHb2IVBiOpVyYiKmpsqJ6fTHdPjw4SYvjfSkoe63336roKAgr9dLSkpSWFiYWxn7iZhOprxRPa9qnUaTJk3S2LFjlZ6ergEDBuiFF17QoUOHlJOTI0m67bbbFB8frxkzZkiS8vPztWvXLqWmpmrXrl2aNm2aHA6HJk+e7HWb27dv19tvv62srCxFR0dr48aNuv/++zV48GAlJyef/jcBAAA/VlRUpLS0tGavN3bs2GbVLygoUL9+/Zq9HeBEfC5BHjNmjMrKyjRlyhTt3r1bqampWrFihfMmu5KSErcjjurqauXm5qq4uFjh4eHKysrS/PnzFRUV5XWbQUFB+uijj5yJc9euXZWdna3c3NzTGjsAAIEgKSlJBQUFXtc/ePCgVq1apSFDhig8PLxZ2wFag09dg+zPqqqqFBkZecJrWoBTtX79eqWlpXHmBACAZvI2X/OpeZABnFjDMS3HtgAChWEY2r9/P+MafAYJMuBnGu7MPfYOXQDwV3a7XUVFRYxr8BkkyAAAAIALEmQAAADABQky4GdMJpPbKwD4O5PJpNDQUMY1+Ayfm+YNwPE1TJbe1KTpAOBvLBaLUlJS2robgBNnkAE/0/BoTtdHdAKAP3M4HNq7dy/jGnwGCTLgZ0iQAQQah8Oh4uJixjX4DBJkAAAAwAUJMgAAAOCCBBnwM8xiASDQmEwmRUZGMq7BZzCLBeBnmMUCQKCxWCzq1atXW3cDcOIMMuBnuEkPQKBxOBzauXMn4xp8Bgky4GdIkAEEGhJk+BoSZAAAAMAFCTIAAADgggQZ8DNms9ntFQD8ndlsVkxMDOMafAazWAB+hgQZQKAxm82y2Wxt3Q3AiW9YwM9wkx6AQONwOLR9+3bGNfgMEmTAz5AgAwg0DodDZWVljGvwGSTIAAAAgAsSZAAAAMAFCTLgZ7hJD0CgMZvNSkhIYFyDz2AWC8DPkCADCDQNCTLgK/iGBfyM3W53ewUAf2e327V161bGNfgMEmTAzxiG4fYKAP7OMAxVVlYyrsFnkCADAAAALkiQAQAAABckyICf4SY9AIHGbDYrMTGRcQ0+g1ksAD9Dggwg0JjNZnXu3LmtuwE48Q0L+BlmsQAQaOx2u77++mvGNfgMEmTAzzCLBYBAYxiGjhw5wrgGn0GCDAAAALggQQYAAABckCADfsZisbi9AoC/s1gsSkpKYlyDz2AWC8DPmEwmt1cA8Hcmk0lRUVFt3Q3AiTPIgJ+pr693ewUAf1dfX6+vvvqKcQ0+gwQZAAC0OaZ4gy8hQQYAAABckCADAAAALkiQAT/DLBYAAo3FYlFycjLjGnwGCTIAAGhzQUFBbd0FwIkEGfAzDTeycEMLgEBht9u1bt06xjX4DBJkAAAAwAUJMgAAAOCCBBkAAABw4ZMJ8uzZs9WjRw+FhIQoIyNDa9eubbJuXV2dnnjiCdlsNoWEhCglJUUrVqxodpvV1dW6++67FR0drfDwcGVnZ2vPnj0tHhtwqpjFAkCgsVgsSk9PZ1yDz/C5BHnBggWaNGmSpk6dqvXr1yslJUWZmZnau3evx/q5ubl6+eWX9eKLL2rLli0aP368Ro8ercLCwma1ef/992vZsmV69913tWrVKpWWluraa69t9XgBAIBUW1vb1l0AnEyGYRht3QlXGRkZ6t+/v/76179KkhwOh7p27ap77rlHDz/8cKP6cXFxeuyxx3T33Xc7y7KzsxUaGqo333zTqzYrKysVExOjt99+W9ddd50kqaioSL169dKaNWt0wQUXnLDfVVVVioyMVGVlpSIiIk75fQCasnbtWmVkZCg/P18DBgxo6+4AwCmrr6/XunXrlJ6eLqvV2tbdQQDzNl/zqU9hbW2tCgoK9MgjjzjLzGazhg8frjVr1nhcp6amRiEhIW5loaGhWr16tddtFhQUqK6uTsOHD3fWSUpKUrdu3ZpMkGtqalRTU+P8uaqqStLRX/L6+nrndsxmsxwOhxwOh9v2zWaz7Ha7XI9Pmiq3WCwymUzOdl3LpcbTfTVVbrVaZRiGW7nJZJLFYmnUx6bKicl3YnI4HLLb7QEV0/HKiYmYiClwY5IUcDEF4n4KhJiOrd8Un0qQy8vLZbfb1aVLF7fyLl26qKioyOM6mZmZmjlzpgYPHiybzaa8vDwtWrTI+cZ40+bu3bsVFBSkqKioRnV2797tcbszZszQ9OnTG5UXFhaqffv2kqSYmBjZbDbt2LFDZWVlzjoJCQlKSEjQt99+q8rKSmd5YmKiOnfurE2bNunIkSPO8qSkJEVFRamwsNBthycnJysoKEjr1q1z60N6erpqa2u1ceNGZ5nFYlH//v1VWVnp9l6GhoYqJSVF5eXlKi4udpZHRkaqV69eKi0t1c6dO53lxNT2MTWUFxUVBUxMgbifiImYiMn7mPr27av6+nqtX79eJpMpIGIKxP0UCDG5XoJ7PD51iUVpaani4+P1xRdfaODAgc7yyZMna9WqVcrPz2+0TllZmcaNG6dly5bJZDLJZrNp+PDhmjdvno4cOeJVm2+//bZycnLczghL0oABAzR06FD96U9/arRdT2eQu3btqoqKCucp+7Y+SgrEIz9icmjt2rUaOHCg1qxZo/79+wdETIG4n4iJmIipeWeQG+4Raqjj7zEF4n4KhJj27dun6Oho/7rEolOnTrJYLI1mj9izZ49iY2M9rhMTE6MlS5aourpaFRUViouL08MPP6zExESv24yNjVVtba3279/vdhb5eNsNDg5WcHBwo3Kr1dro+qmGnXushp3lbXlT12U1p9xkMnksb6qPzS0nptaPqeFxrEFBQc4++HtMgbifiImYiKl55U3dU+HPMQXifgrEmDzW86rWaRIUFKS0tDTl5eVp1KhRko5eZ5mXl6eJEyced92QkBDFx8errq5OCxcu1A033OB1m2lpaWrXrp3y8vKUnZ0tSdq2bZtKSkrczjoDreHw4cNNXkLkydatW91evZWUlKSwsLBmrQMAp4NhGKqsrFRkZKTzEgugLflUgixJkyZN0tixY5Wenq4BAwbohRde0KFDh5STkyNJuu222xQfH68ZM2ZIkvLz87Vr1y6lpqZq165dmjZtmhwOhyZPnux1m5GRkbrjjjs0adIkdezYUREREbrnnns0cOBAr2awAE5FUVGR0tLSmr3eLbfc0qz6BQUF6tevX7O3AwCtzW63q6ioiFks4DN87lM4ZswYlZWVacqUKdq9e7dSU1O1YsUK5012JSUlbqfkq6urlZubq+LiYoWHhysrK0vz5893u1TiRG1K0vPPPy+z2azs7GzV1NQoMzNTf/vb305b3Pj1SkpKUkFBgdf1Dx48qE8++URDhw5VeHh4s7YDAABOzKdu0vNnzIOM04X5QgEEGsY1nC7e5ms+9yQ9AMdnMpkUGhrKdXoAAgbjGnwNh2mAn7FYLEpJSWnrbgBAi2Fcg6/hDDLgZxwOh/bu3es2fyQA+DPGNfgaEmTAzzgcDhUXF/NFAiBgMK7B15AgAwAAAC5IkAEAAAAXJMiAnzGZTDxtCkBAYVyDr2EWC8DPWCwW9erVq627AQAthnENvoYzyICfcTgc2rlzJzezAAgYjGvwNSTIgJ/hiwRAoGFcg68hQQYAAABckCADAAAALkiQAT9jNpsVExMjs5lfXwCBgXENvoZZLAA/YzabZbPZ2robANBiGNfgazhUA/yMw+HQ9u3buZkFQMBgXIOvIUEG/IzD4VBZWRlfJAACBuMafA0JMgAAAOCCa5BbiGEYkqSqqqo27gkCXX19vQ4dOqSqqipZrfwKA/B/jGs4XRrytIa8rSl8ClvIgQMHJEldu3Zt454AAADgeA4cOKDIyMgml5uME6XQ8IrD4VBpaak6dOggk8nU1t1BAKuqqlLXrl31008/KSIioq27AwCnjHENp4thGDpw4IDi4uKOO60gZ5BbiNlsVkJCQlt3A78iERERfJEACCiMazgdjnfmuAE36QEAAAAuSJABAAAAFyTIgJ8JDg7W1KlTFRwc3NZdAYAWwbgGX8NNegAAAIALziADAAAALkiQAQAAABckyAAAAIALEmSglZlMJi1ZssTr+q+99pqioqKaXL5y5UqZTCbt37//lPsGAAAaI0EGTlFZWZkmTJigbt26KTg4WLGxscrMzNTnn38uSfr55581YsSINu4lALSNNWvWyGKx6Morr2y0bPHixbrgggsUGRmpDh06qE+fPrrvvvskSZdccolMJlOT/y655JLTGwh+VXiSHnCKsrOzVVtbq9dff12JiYnas2eP8vLyVFFRIUmKjY1t4x56p66uTu3atWvrbgAIMHPnztU999yjuXPnqrS0VHFxcZKkvLw8jRkzRk8//bSuvvpqmUwmbdmyRR9++KEkadGiRaqtrZUk/fTTTxowYIA++ugj9enTR5IUFBTUNgHhV4EzyMAp2L9/vz777DP96U9/0tChQ9W9e3cNGDBAjzzyiK6++mpJ7pdY/PDDDzKZTFq0aJGGDh2qsLAwpaSkaM2aNU1uo6ysTOnp6Ro9erRqamqc5QUFBUpPT1dYWJgGDRqkbdu2ua03Z84c2Ww2BQUF6dxzz9X8+fPdlptMJs2ZM0dXX3212rdvr6efflrTpk1Tamqq5s+frx49eigyMlI33nijDhw40ELvGIBfk4MHD2rBggWaMGGCrrzySr322mvOZcuWLdOFF16oBx98UOeee67OOeccjRo1SrNnz5YkdezYUbGxsYqNjVVMTIwkKTo62lnWsWPHtggJvxIkyMApCA8PV3h4uJYsWeKWvJ7IY489pj/+8Y/asGGDzjnnHN10002qr69vVO+nn37SxRdfrPPOO0/vvfee2yT6jz32mJ577jmtW7dOVqtVv/3tb53LFi9erHvvvVcPPPCANm3apLvuuks5OTn65JNP3NqfNm2aRo8erW+++ca5/vbt27VkyRItX75cy5cv16pVq/TMM880960BAL3zzjtKSkrSueeeq1tuuUXz5s1Tw+MXYmNjtXnzZm3atKmNewl4YAA4Je+9955xxhlnGCEhIcagQYOMRx55xPj666+dyyUZixcvNgzDMHbs2GFIMv7+9787l2/evNmQZGzdutUwDMN49dVXjcjISKOoqMjo2rWr8Yc//MFwOBzO+p988okhyfjoo4+cZe+//74hyThy5IhhGIYxaNAgY9y4cW79vP76642srCy3ft13331udaZOnWqEhYUZVVVVzrIHH3zQyMjIONm3B8Cv2KBBg4wXXnjBMAzDqKurMzp16mR88sknhmEYxsGDB42srCxDktG9e3djzJgxxty5c43q6upG7TSMnYWFhaex9/g14wwycIqys7NVWlqqf/3rX7riiiu0cuVK9evXz+1PicdKTk52/v/MM8+UJO3du9dZduTIEV188cW69tprNWvWLJlMpma1sXXrVl144YVu9S+88EJt3brVrSw9Pb1Ruz169FCHDh3c2nbtGwB4Y9u2bVq7dq1uuukmSZLVatWYMWM0d+5cSVL79u31/vvv6/vvv1dubq7Cw8P1wAMPaMCAATp8+HBbdh3gEgugJYSEhOiyyy7T448/ri+++EK33367pk6d2mR915vhGpJfh8PhLAsODtbw4cO1fPly7dq166Ta8Eb79u2P225D281tFwDmzp2r+vp6xcXFyWq1ymq1as6cOVq4cKEqKyud9Ww2m373u9/p73//u9avX68tW7ZowYIFbdhzgAQZaBW9e/fWoUOHTnp9s9ms+fPnKy0tTUOHDlVpaWmz1u/Vq5dzmrkGn3/+uXr37n3SfQIAb9XX1+uNN97Qc889pw0bNjj/ff3114qLi9M//vEPj+v16NFDYWFhpzR+Ai2Bad6AU1BRUaHrr79ev/3tb5WcnKwOHTpo3bp1evbZZ3XNNdecUtsWi0VvvfWWbrrpJl166aVauXKl11PGPfjgg7rhhhvUt29fDR8+XMuWLdOiRYv00UcfnVKfAMAby5cv1759+3THHXcoMjLSbVl2drbmzp2r3bt36/Dhw8rKylL37t21f/9+/eUvf1FdXZ0uu+yyNuo5cBRnkIFTEB4eroyMDD3//PMaPHiwzjvvPD3++OMaN26c/vrXv55y+1arVf/4xz/Up08fXXrppV5fCzxq1CjNmjVL//Vf/6U+ffro5Zdf1quvvsrE+gBOi7lz52r48OGNkmPpaIK8bt06nXHGGSouLtZtt92mpKQkjRgxQrt379Z//vMfnXvuuW3Qa+D/mAzjf+dbAQAAAMAZZAAAAMAVCTIAAADgggQZAAAAcEGCDAAAALggQQYAAABckCADAAAALkiQAQAAABckyAAAAIALEmQAAADABQkyAAAA4IIEGQAAAHBBggwAAAC4+P9jHNvV4ZhpMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Run Experiments\n",
    "def run_comparison_experiment(loops=10):\n",
    "    \"\"\"\n",
    "    Runs a full comparison between Sinkhorn DRO (SGD) and AST models.\n",
    "    \"\"\"\n",
    "    scores = {'Sinkhorn': [], 'AST': []}\n",
    "    \n",
    "    device = \"0\"\n",
    "    print(f\"\\nRunning all experiments on device: '{device}'\")\n",
    "\n",
    "    for i in range(loops):\n",
    "        print(f\"\\n{'='*20} Experiment {i+1}/{loops} {'='*20}\")\n",
    "        \n",
    "        # Generate data\n",
    "        X_train, y_train = generate_imbalanced_data(n_samples=500, noise_level=0.1)\n",
    "        X_test, y_test = generate_balanced_data(n_samples=2000, noise_level=0.1)\n",
    "        print(f\"Training data: {len(X_train)} samples ({np.mean(y_train):.1%} positive)\")\n",
    "        print(f\"Test data: {len(X_test)} samples\")\n",
    "\n",
    "        params_dict = {'Sinkhorn': None, 'AST': None}\n",
    "        loss_histories = {'Sinkhorn': [], 'AST': []}\n",
    "\n",
    "        # --- Train and Evaluate Sinkhorn DRO ---\n",
    "        print(\"\\nTraining Sinkhorn DRO (SGD)...\")\n",
    "        try:\n",
    "            model_sdro = SinkhornLinearDRO(\n",
    "                input_dim=2, reg_param=1e-2, lambda_param=100.0,\n",
    "                max_iter=50, learning_rate=1e-2, k_sample_max=3, device=device\n",
    "            )\n",
    "            params_dict['Sinkhorn'], loss_histories['Sinkhorn'] = model_sdro.fit(X_train, y_train)\n",
    "            _, f1 = model_sdro.score(X_test, y_test)\n",
    "            scores['Sinkhorn'].append(f1)\n",
    "            print(f\"Sinkhorn DRO Final F1-Score: {f1:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Sinkhorn DRO training failed: {e}\")\n",
    "            scores['Sinkhorn'].append(0)\n",
    "\n",
    "        # --- Train and Evaluate AST ---\n",
    "        print(\"\\nTraining AST Sampler DRO...\")\n",
    "        try:\n",
    "            model_ast = SinkhornDROLogisticAST(\n",
    "                input_dim=2, epsilon=0.01, lambda_dro=100.0, \n",
    "                ast_n_steps=50, ast_n_svgd=1, num_ast_samples=8,\n",
    "                max_iter=50, learning_rate=0.01, device=device\n",
    "            )\n",
    "            params_dict['AST'], loss_histories['AST'] = model_ast.fit(X_train, y_train)\n",
    "            _, f1 = model_ast.score(X_test, y_test)\n",
    "            scores['AST'].append(f1)\n",
    "            print(f\"AST DRO Final F1-Score: {f1:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"AST training failed: {e}\")\n",
    "            scores['AST'].append(0)\n",
    "\n",
    "        # Analyze and plot boundaries for the current experiment\n",
    "        for name, params in params_dict.items():\n",
    "            if params:\n",
    "                analyze_decision_boundary(params, X_test, y_test, name)\n",
    "        plot_decision_boundaries(X_train, y_train, params_dict, i)\n",
    "        \n",
    "        # Plot loss convergence for the current experiment\n",
    "        plot_loss_convergence(loss_histories, i)\n",
    "\n",
    "\n",
    "    # --- Final Results ---\n",
    "    print(f\"\\n{'='*25} Final Results over {loops} Experiments {'='*25}\")\n",
    "    for name, f1_scores in scores.items():\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "        print(f\"{name} Average F1-Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    \n",
    "    # Plot final performance comparison\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(list(scores.values()), labels=list(scores.keys()), patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "    plt.title('Model Performance Comparison', fontsize=16)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    plt.savefig('final_performance_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "run_comparison_experiment(loops=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
